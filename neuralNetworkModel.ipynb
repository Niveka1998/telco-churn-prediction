{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-11T23:52:23.551206Z",
     "start_time": "2025-12-11T23:52:23.538969Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "from keras import layers, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.makedirs('results/figures', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T23:56:58.701866Z",
     "start_time": "2025-12-11T23:56:58.692644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#neural network classifier\n",
    "print(\"Neural network classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#load preprocessed data\n",
    "print(\"Step 1: Loading preprocesses data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('models/preprocessed_data.pkl','rb') as f:\n",
    "    preprocessed_data= pickle.load(f)\n",
    "\n",
    "feature_names = preprocessed_data['feature_names']\n",
    "X_train = preprocessed_data['X_train']\n",
    "X_test = preprocessed_data['X_test']\n",
    "y_train = preprocessed_data['y_train']\n",
    "y_test= preprocessed_data['y_test']\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"Training data samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Class distribution (train): {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution (test): {np.bincount(y_test)}\")\n",
    "\n",
    "input_dimension = X_train.shape[1]\n",
    "print(f\"\\nInput dimension for neural network: {input_dimension}\")\n"
   ],
   "id": "2831dd684aa4d2f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classifier\n",
      "============================================================\n",
      "Step 1: Loading preprocesses data\n",
      "============================================================\n",
      "Data loaded successfully.\n",
      "Training data samples: 8278\n",
      "Test samples: 1409\n",
      "Features: 19\n",
      "Class distribution (train): [4139 4139]\n",
      "Class distribution (test): [1035  374]\n",
      "\n",
      "Input dimension for neural network: 19\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:19:36.379026Z",
     "start_time": "2025-12-12T00:19:36.368636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#define neural network architecture\n",
    "print(\"Step 2: Neural network architecture design\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def create_nn_model(hidden_layers=[64,32], dropout_rate=0.3, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    create a nural network model with specified architecture\n",
    "    Parameters:\n",
    "    :param hidden_layers: list of integers [neurons in each hidden layer]\n",
    "    :param dropout_rate: dropout rate for regularization\n",
    "    :param learning_rate: learning rate for optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential(name='ChurnPredictionNN')\n",
    "\n",
    "    #Input layer\n",
    "    model.add(Dense(hidden_layers[0], activation='relu', input_dim=input_dimension))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    #hidden layers\n",
    "    for i, units in enumerate(hidden_layers[1:], start=2):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "    #compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                 keras.metrics.Precision(),\n",
    "                 keras.metrics.Recall(),\n",
    "                 keras.metrics.AUC()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "1be4286dfd91807a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Neural network architecture design\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:21:39.193231Z",
     "start_time": "2025-12-12T00:20:32.973317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#baseline model\n",
    "print(\"Step 3: Baseline neural network model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Architecture: [64, 32] neurons, dropout=0.3, learning_rate=0.001\")\n",
    "\n",
    "#create baseline model\n",
    "bs_model = create_nn_model(hidden_layers=[64,32], dropout_rate=0.3, learning_rate=0.001)\n",
    "\n",
    "#display model architecture\n",
    "print(\"\\nModel architecture:\")\n",
    "bs_model.summary()\n",
    "\n",
    "#define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#train baseline\n",
    "print(\"\\nTraining baseline model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_baseline = bs_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\nBaseline model training completed\")\n",
    "\n",
    "#make prediction\n",
    "y_pred_prob_baseline = bs_model.predict(X_test, verbose=0).flatten()\n",
    "y_pred_baseline = (y_pred_prob_baseline > 0.5).astype(int)\n",
    "\n",
    "#evaluate baseline model\n",
    "print(\"Baseline model performance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bs_accuracy= accuracy_score(y_test, y_pred_baseline) #percentage of correct predictions\n",
    "\n",
    "bs_precision = precision_score(y_test, y_pred_baseline) #Of all predicted \"Churn\" customers, how many actually churned?\n",
    "\n",
    "bs_recall = recall_score(y_test, y_pred_baseline)#Of all actual churners, how many did the model detect?\n",
    "\n",
    "bs_f1 = f1_score(y_test, y_pred_baseline) #Harmonic mean of Precision & Recall\n",
    "\n",
    "bs_roc_auc = roc_auc_score(y_test, y_pred_prob_baseline)\n",
    "#Measures overall ranking ability of the model: [0.5 - random guessing, 1- perfect]\n",
    "\n",
    "print(f\"Accuracy: {bs_accuracy:.4f}\")\n",
    "print(f\"Precision: {bs_precision:.4f}\")\n",
    "print(f\"Recall: {bs_recall:.4f}\")\n",
    "print(f\"F1-Score: {bs_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {bs_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_baseline, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(cm)\n",
    "\n"
   ],
   "id": "9afb416ecee67b14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Baseline neural network model\n",
      "============================================================\n",
      "Architecture: [64, 32] neurons, dropout=0.3, learning_rate=0.001\n",
      "\n",
      "Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"ChurnPredictionNN\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ChurnPredictionNN\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m1,280\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001B[38;5;33mDense\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3,777\u001B[0m (14.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,585\u001B[0m (14.00 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,585</span> (14.00 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m192\u001B[0m (768.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline model\n",
      "============================================================\n",
      "Epoch 1/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.6927 - auc_1: 0.7483 - loss: 0.6192 - precision_1: 0.5776 - recall_1: 0.6714 - val_accuracy: 0.7391 - val_auc_1: 0.0000e+00 - val_loss: 0.5817 - val_precision_1: 1.0000 - val_recall_1: 0.7391\n",
      "Epoch 2/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7452 - auc_1: 0.8103 - loss: 0.5204 - precision_1: 0.6582 - recall_1: 0.6669 - val_accuracy: 0.7434 - val_auc_1: 0.0000e+00 - val_loss: 0.5612 - val_precision_1: 1.0000 - val_recall_1: 0.7434\n",
      "Epoch 3/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7496 - auc_1: 0.8177 - loss: 0.5077 - precision_1: 0.6672 - recall_1: 0.6629 - val_accuracy: 0.7560 - val_auc_1: 0.0000e+00 - val_loss: 0.5523 - val_precision_1: 1.0000 - val_recall_1: 0.7560\n",
      "Epoch 4/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7563 - auc_1: 0.8286 - loss: 0.4905 - precision_1: 0.6773 - recall_1: 0.6685 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5466 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 5/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7625 - auc_1: 0.8349 - loss: 0.4823 - precision_1: 0.6859 - recall_1: 0.6762 - val_accuracy: 0.7609 - val_auc_1: 0.0000e+00 - val_loss: 0.5377 - val_precision_1: 1.0000 - val_recall_1: 0.7609\n",
      "Epoch 6/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7691 - auc_1: 0.8410 - loss: 0.4731 - precision_1: 0.6950 - recall_1: 0.6847 - val_accuracy: 0.7446 - val_auc_1: 0.0000e+00 - val_loss: 0.5601 - val_precision_1: 1.0000 - val_recall_1: 0.7446\n",
      "Epoch 7/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7676 - auc_1: 0.8396 - loss: 0.4753 - precision_1: 0.6955 - recall_1: 0.6762 - val_accuracy: 0.7428 - val_auc_1: 0.0000e+00 - val_loss: 0.5513 - val_precision_1: 1.0000 - val_recall_1: 0.7428\n",
      "Epoch 8/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7724 - auc_1: 0.8428 - loss: 0.4714 - precision_1: 0.7015 - recall_1: 0.6843 - val_accuracy: 0.7512 - val_auc_1: 0.0000e+00 - val_loss: 0.5446 - val_precision_1: 1.0000 - val_recall_1: 0.7512\n",
      "Epoch 9/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7762 - auc_1: 0.8475 - loss: 0.4652 - precision_1: 0.7054 - recall_1: 0.6923 - val_accuracy: 0.7518 - val_auc_1: 0.0000e+00 - val_loss: 0.5428 - val_precision_1: 1.0000 - val_recall_1: 0.7518\n",
      "Epoch 10/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7759 - auc_1: 0.8481 - loss: 0.4651 - precision_1: 0.7056 - recall_1: 0.6903 - val_accuracy: 0.7379 - val_auc_1: 0.0000e+00 - val_loss: 0.5591 - val_precision_1: 1.0000 - val_recall_1: 0.7379\n",
      "Epoch 11/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7724 - auc_1: 0.8476 - loss: 0.4661 - precision_1: 0.7033 - recall_1: 0.6798 - val_accuracy: 0.7530 - val_auc_1: 0.0000e+00 - val_loss: 0.5431 - val_precision_1: 1.0000 - val_recall_1: 0.7530\n",
      "Epoch 12/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7762 - auc_1: 0.8476 - loss: 0.4649 - precision_1: 0.7024 - recall_1: 0.6996 - val_accuracy: 0.7560 - val_auc_1: 0.0000e+00 - val_loss: 0.5469 - val_precision_1: 1.0000 - val_recall_1: 0.7560\n",
      "Epoch 13/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7810 - auc_1: 0.8548 - loss: 0.4551 - precision_1: 0.7133 - recall_1: 0.6955 - val_accuracy: 0.7536 - val_auc_1: 0.0000e+00 - val_loss: 0.5524 - val_precision_1: 1.0000 - val_recall_1: 0.7536\n",
      "Epoch 14/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7794 - auc_1: 0.8522 - loss: 0.4596 - precision_1: 0.7099 - recall_1: 0.6959 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5458 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 15/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7800 - auc_1: 0.8555 - loss: 0.4540 - precision_1: 0.7099 - recall_1: 0.6988 - val_accuracy: 0.7591 - val_auc_1: 0.0000e+00 - val_loss: 0.5397 - val_precision_1: 1.0000 - val_recall_1: 0.7591\n",
      "Epoch 16/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7831 - auc_1: 0.8553 - loss: 0.4547 - precision_1: 0.7164 - recall_1: 0.6979 - val_accuracy: 0.7603 - val_auc_1: 0.0000e+00 - val_loss: 0.5349 - val_precision_1: 1.0000 - val_recall_1: 0.7603\n",
      "Epoch 17/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7828 - auc_1: 0.8532 - loss: 0.4576 - precision_1: 0.7146 - recall_1: 0.7008 - val_accuracy: 0.7482 - val_auc_1: 0.0000e+00 - val_loss: 0.5451 - val_precision_1: 1.0000 - val_recall_1: 0.7482\n",
      "Epoch 18/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7798 - auc_1: 0.8574 - loss: 0.4520 - precision_1: 0.7140 - recall_1: 0.6887 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5319 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 19/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7791 - auc_1: 0.8579 - loss: 0.4517 - precision_1: 0.7120 - recall_1: 0.6899 - val_accuracy: 0.7482 - val_auc_1: 0.0000e+00 - val_loss: 0.5449 - val_precision_1: 1.0000 - val_recall_1: 0.7482\n",
      "Epoch 20/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7853 - auc_1: 0.8598 - loss: 0.4486 - precision_1: 0.7172 - recall_1: 0.7056 - val_accuracy: 0.7530 - val_auc_1: 0.0000e+00 - val_loss: 0.5370 - val_precision_1: 1.0000 - val_recall_1: 0.7530\n",
      "Epoch 21/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7848 - auc_1: 0.8599 - loss: 0.4495 - precision_1: 0.7173 - recall_1: 0.7032 - val_accuracy: 0.7476 - val_auc_1: 0.0000e+00 - val_loss: 0.5478 - val_precision_1: 1.0000 - val_recall_1: 0.7476\n",
      "Epoch 22/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7887 - auc_1: 0.8635 - loss: 0.4442 - precision_1: 0.7262 - recall_1: 0.7008 - val_accuracy: 0.7554 - val_auc_1: 0.0000e+00 - val_loss: 0.5372 - val_precision_1: 1.0000 - val_recall_1: 0.7554\n",
      "Epoch 23/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7871 - auc_1: 0.8643 - loss: 0.4416 - precision_1: 0.7203 - recall_1: 0.7064 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5221 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 24/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7878 - auc_1: 0.8608 - loss: 0.4485 - precision_1: 0.7248 - recall_1: 0.7000 - val_accuracy: 0.7591 - val_auc_1: 0.0000e+00 - val_loss: 0.5280 - val_precision_1: 1.0000 - val_recall_1: 0.7591\n",
      "Epoch 25/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7912 - auc_1: 0.8646 - loss: 0.4423 - precision_1: 0.7265 - recall_1: 0.7104 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5321 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 26/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7896 - auc_1: 0.8632 - loss: 0.4442 - precision_1: 0.7280 - recall_1: 0.7008 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5325 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 27/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7948 - auc_1: 0.8665 - loss: 0.4391 - precision_1: 0.7363 - recall_1: 0.7052 - val_accuracy: 0.7585 - val_auc_1: 0.0000e+00 - val_loss: 0.5367 - val_precision_1: 1.0000 - val_recall_1: 0.7585\n",
      "Epoch 28/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7892 - auc_1: 0.8626 - loss: 0.4456 - precision_1: 0.7249 - recall_1: 0.7056 - val_accuracy: 0.7687 - val_auc_1: 0.0000e+00 - val_loss: 0.5216 - val_precision_1: 1.0000 - val_recall_1: 0.7687\n",
      "Epoch 29/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7898 - auc_1: 0.8637 - loss: 0.4436 - precision_1: 0.7238 - recall_1: 0.7104 - val_accuracy: 0.7554 - val_auc_1: 0.0000e+00 - val_loss: 0.5242 - val_precision_1: 1.0000 - val_recall_1: 0.7554\n",
      "Epoch 30/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7949 - auc_1: 0.8636 - loss: 0.4438 - precision_1: 0.7362 - recall_1: 0.7060 - val_accuracy: 0.7615 - val_auc_1: 0.0000e+00 - val_loss: 0.5230 - val_precision_1: 1.0000 - val_recall_1: 0.7615\n",
      "Epoch 31/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7916 - auc_1: 0.8668 - loss: 0.4392 - precision_1: 0.7263 - recall_1: 0.7128 - val_accuracy: 0.7585 - val_auc_1: 0.0000e+00 - val_loss: 0.5287 - val_precision_1: 1.0000 - val_recall_1: 0.7585\n",
      "Epoch 32/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7933 - auc_1: 0.8666 - loss: 0.4394 - precision_1: 0.7313 - recall_1: 0.7092 - val_accuracy: 0.7627 - val_auc_1: 0.0000e+00 - val_loss: 0.5239 - val_precision_1: 1.0000 - val_recall_1: 0.7627\n",
      "Epoch 33/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7912 - auc_1: 0.8685 - loss: 0.4363 - precision_1: 0.7262 - recall_1: 0.7112 - val_accuracy: 0.7621 - val_auc_1: 0.0000e+00 - val_loss: 0.5288 - val_precision_1: 1.0000 - val_recall_1: 0.7621\n",
      "Epoch 34/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7933 - auc_1: 0.8693 - loss: 0.4359 - precision_1: 0.7281 - recall_1: 0.7161 - val_accuracy: 0.7754 - val_auc_1: 0.0000e+00 - val_loss: 0.5157 - val_precision_1: 1.0000 - val_recall_1: 0.7754\n",
      "Epoch 35/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7940 - auc_1: 0.8669 - loss: 0.4390 - precision_1: 0.7298 - recall_1: 0.7157 - val_accuracy: 0.7723 - val_auc_1: 0.0000e+00 - val_loss: 0.5245 - val_precision_1: 1.0000 - val_recall_1: 0.7723\n",
      "Epoch 36/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7990 - auc_1: 0.8719 - loss: 0.4315 - precision_1: 0.7349 - recall_1: 0.7257 - val_accuracy: 0.7705 - val_auc_1: 0.0000e+00 - val_loss: 0.5134 - val_precision_1: 1.0000 - val_recall_1: 0.7705\n",
      "Epoch 37/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7955 - auc_1: 0.8686 - loss: 0.4369 - precision_1: 0.7314 - recall_1: 0.7185 - val_accuracy: 0.7717 - val_auc_1: 0.0000e+00 - val_loss: 0.5202 - val_precision_1: 1.0000 - val_recall_1: 0.7717\n",
      "Epoch 38/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7937 - auc_1: 0.8692 - loss: 0.4360 - precision_1: 0.7273 - recall_1: 0.7197 - val_accuracy: 0.7693 - val_auc_1: 0.0000e+00 - val_loss: 0.5188 - val_precision_1: 1.0000 - val_recall_1: 0.7693\n",
      "Epoch 39/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7951 - auc_1: 0.8727 - loss: 0.4296 - precision_1: 0.7338 - recall_1: 0.7116 - val_accuracy: 0.7681 - val_auc_1: 0.0000e+00 - val_loss: 0.5105 - val_precision_1: 1.0000 - val_recall_1: 0.7681\n",
      "Epoch 40/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7949 - auc_1: 0.8695 - loss: 0.4337 - precision_1: 0.7288 - recall_1: 0.7217 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5264 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 41/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8013 - auc_1: 0.8706 - loss: 0.4342 - precision_1: 0.7406 - recall_1: 0.7233 - val_accuracy: 0.7657 - val_auc_1: 0.0000e+00 - val_loss: 0.5170 - val_precision_1: 1.0000 - val_recall_1: 0.7657\n",
      "Epoch 42/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7981 - auc_1: 0.8730 - loss: 0.4298 - precision_1: 0.7346 - recall_1: 0.7225 - val_accuracy: 0.7729 - val_auc_1: 0.0000e+00 - val_loss: 0.5080 - val_precision_1: 1.0000 - val_recall_1: 0.7729\n",
      "Epoch 43/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8023 - auc_1: 0.8775 - loss: 0.4241 - precision_1: 0.7414 - recall_1: 0.7261 - val_accuracy: 0.7772 - val_auc_1: 0.0000e+00 - val_loss: 0.5011 - val_precision_1: 1.0000 - val_recall_1: 0.7772\n",
      "Epoch 44/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7984 - auc_1: 0.8730 - loss: 0.4289 - precision_1: 0.7339 - recall_1: 0.7253 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4951 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 45/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7982 - auc_1: 0.8749 - loss: 0.4268 - precision_1: 0.7359 - recall_1: 0.7205 - val_accuracy: 0.7742 - val_auc_1: 0.0000e+00 - val_loss: 0.5033 - val_precision_1: 1.0000 - val_recall_1: 0.7742\n",
      "Epoch 46/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7993 - auc_1: 0.8742 - loss: 0.4279 - precision_1: 0.7346 - recall_1: 0.7277 - val_accuracy: 0.7802 - val_auc_1: 0.0000e+00 - val_loss: 0.4984 - val_precision_1: 1.0000 - val_recall_1: 0.7802\n",
      "Epoch 47/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8001 - auc_1: 0.8781 - loss: 0.4217 - precision_1: 0.7364 - recall_1: 0.7269 - val_accuracy: 0.7760 - val_auc_1: 0.0000e+00 - val_loss: 0.4965 - val_precision_1: 1.0000 - val_recall_1: 0.7760\n",
      "Epoch 48/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8014 - auc_1: 0.8765 - loss: 0.4245 - precision_1: 0.7384 - recall_1: 0.7286 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4873 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 49/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7998 - auc_1: 0.8783 - loss: 0.4215 - precision_1: 0.7362 - recall_1: 0.7261 - val_accuracy: 0.7844 - val_auc_1: 0.0000e+00 - val_loss: 0.4870 - val_precision_1: 1.0000 - val_recall_1: 0.7844\n",
      "Epoch 50/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7987 - auc_1: 0.8763 - loss: 0.4244 - precision_1: 0.7388 - recall_1: 0.7165 - val_accuracy: 0.7736 - val_auc_1: 0.0000e+00 - val_loss: 0.5033 - val_precision_1: 1.0000 - val_recall_1: 0.7736\n",
      "Epoch 51/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8038 - auc_1: 0.8784 - loss: 0.4219 - precision_1: 0.7442 - recall_1: 0.7265 - val_accuracy: 0.7699 - val_auc_1: 0.0000e+00 - val_loss: 0.5148 - val_precision_1: 1.0000 - val_recall_1: 0.7699\n",
      "Epoch 52/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8020 - auc_1: 0.8752 - loss: 0.4264 - precision_1: 0.7419 - recall_1: 0.7237 - val_accuracy: 0.7681 - val_auc_1: 0.0000e+00 - val_loss: 0.5001 - val_precision_1: 1.0000 - val_recall_1: 0.7681\n",
      "Epoch 53/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8023 - auc_1: 0.8812 - loss: 0.4171 - precision_1: 0.7416 - recall_1: 0.7257 - val_accuracy: 0.7748 - val_auc_1: 0.0000e+00 - val_loss: 0.5061 - val_precision_1: 1.0000 - val_recall_1: 0.7748\n",
      "Epoch 54/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8091 - auc_1: 0.8830 - loss: 0.4152 - precision_1: 0.7513 - recall_1: 0.7338 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4962 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 55/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8016 - auc_1: 0.8774 - loss: 0.4231 - precision_1: 0.7391 - recall_1: 0.7277 - val_accuracy: 0.7790 - val_auc_1: 0.0000e+00 - val_loss: 0.4945 - val_precision_1: 1.0000 - val_recall_1: 0.7790\n",
      "Epoch 56/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8053 - auc_1: 0.8801 - loss: 0.4179 - precision_1: 0.7445 - recall_1: 0.7322 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4922 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 57/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8046 - auc_1: 0.8807 - loss: 0.4171 - precision_1: 0.7422 - recall_1: 0.7338 - val_accuracy: 0.7729 - val_auc_1: 0.0000e+00 - val_loss: 0.5050 - val_precision_1: 1.0000 - val_recall_1: 0.7729\n",
      "Epoch 58/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8061 - auc_1: 0.8808 - loss: 0.4177 - precision_1: 0.7456 - recall_1: 0.7330 - val_accuracy: 0.7802 - val_auc_1: 0.0000e+00 - val_loss: 0.4946 - val_precision_1: 1.0000 - val_recall_1: 0.7802\n",
      "Epoch 59/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8019 - auc_1: 0.8777 - loss: 0.4221 - precision_1: 0.7401 - recall_1: 0.7269 - val_accuracy: 0.7965 - val_auc_1: 0.0000e+00 - val_loss: 0.4830 - val_precision_1: 1.0000 - val_recall_1: 0.7965\n",
      "Epoch 60/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8072 - auc_1: 0.8824 - loss: 0.4155 - precision_1: 0.7449 - recall_1: 0.7386 - val_accuracy: 0.7826 - val_auc_1: 0.0000e+00 - val_loss: 0.4944 - val_precision_1: 1.0000 - val_recall_1: 0.7826\n",
      "Epoch 61/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8063 - auc_1: 0.8797 - loss: 0.4191 - precision_1: 0.7443 - recall_1: 0.7362 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4958 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 62/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8085 - auc_1: 0.8815 - loss: 0.4168 - precision_1: 0.7516 - recall_1: 0.7310 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4926 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 63/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8097 - auc_1: 0.8845 - loss: 0.4125 - precision_1: 0.7481 - recall_1: 0.7427 - val_accuracy: 0.7874 - val_auc_1: 0.0000e+00 - val_loss: 0.4832 - val_precision_1: 1.0000 - val_recall_1: 0.7874\n",
      "Epoch 64/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8059 - auc_1: 0.8840 - loss: 0.4115 - precision_1: 0.7435 - recall_1: 0.7366 - val_accuracy: 0.7814 - val_auc_1: 0.0000e+00 - val_loss: 0.4890 - val_precision_1: 1.0000 - val_recall_1: 0.7814\n",
      "Epoch 65/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8032 - auc_1: 0.8809 - loss: 0.4183 - precision_1: 0.7400 - recall_1: 0.7326 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4738 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 66/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8102 - auc_1: 0.8867 - loss: 0.4077 - precision_1: 0.7482 - recall_1: 0.7443 - val_accuracy: 0.7941 - val_auc_1: 0.0000e+00 - val_loss: 0.4787 - val_precision_1: 1.0000 - val_recall_1: 0.7941\n",
      "Epoch 67/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8058 - auc_1: 0.8830 - loss: 0.4131 - precision_1: 0.7416 - recall_1: 0.7398 - val_accuracy: 0.7814 - val_auc_1: 0.0000e+00 - val_loss: 0.4858 - val_precision_1: 1.0000 - val_recall_1: 0.7814\n",
      "Epoch 68/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8120 - auc_1: 0.8867 - loss: 0.4094 - precision_1: 0.7558 - recall_1: 0.7366 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4808 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 69/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8137 - auc_1: 0.8866 - loss: 0.4092 - precision_1: 0.7544 - recall_1: 0.7459 - val_accuracy: 0.7862 - val_auc_1: 0.0000e+00 - val_loss: 0.4848 - val_precision_1: 1.0000 - val_recall_1: 0.7862\n",
      "Epoch 70/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8129 - auc_1: 0.8872 - loss: 0.4086 - precision_1: 0.7539 - recall_1: 0.7439 - val_accuracy: 0.7856 - val_auc_1: 0.0000e+00 - val_loss: 0.4847 - val_precision_1: 1.0000 - val_recall_1: 0.7856\n",
      "Epoch 71/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8126 - auc_1: 0.8860 - loss: 0.4100 - precision_1: 0.7518 - recall_1: 0.7467 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4752 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 72/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8096 - auc_1: 0.8851 - loss: 0.4117 - precision_1: 0.7506 - recall_1: 0.7370 - val_accuracy: 0.7874 - val_auc_1: 0.0000e+00 - val_loss: 0.4754 - val_precision_1: 1.0000 - val_recall_1: 0.7874\n",
      "Epoch 73/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8109 - auc_1: 0.8875 - loss: 0.4061 - precision_1: 0.7493 - recall_1: 0.7451 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4771 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 74/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8066 - auc_1: 0.8837 - loss: 0.4124 - precision_1: 0.7453 - recall_1: 0.7354 - val_accuracy: 0.7886 - val_auc_1: 0.0000e+00 - val_loss: 0.4745 - val_precision_1: 1.0000 - val_recall_1: 0.7886\n",
      "Epoch 75/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8179 - auc_1: 0.8906 - loss: 0.4017 - precision_1: 0.7609 - recall_1: 0.7499 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4672 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 76/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8130 - auc_1: 0.8874 - loss: 0.4073 - precision_1: 0.7578 - recall_1: 0.7370 - val_accuracy: 0.7959 - val_auc_1: 0.0000e+00 - val_loss: 0.4683 - val_precision_1: 1.0000 - val_recall_1: 0.7959\n",
      "Epoch 77/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8094 - auc_1: 0.8851 - loss: 0.4113 - precision_1: 0.7501 - recall_1: 0.7374 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4668 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 78/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8103 - auc_1: 0.8887 - loss: 0.4044 - precision_1: 0.7520 - recall_1: 0.7374 - val_accuracy: 0.7959 - val_auc_1: 0.0000e+00 - val_loss: 0.4698 - val_precision_1: 1.0000 - val_recall_1: 0.7959\n",
      "Epoch 79/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8130 - auc_1: 0.8881 - loss: 0.4062 - precision_1: 0.7552 - recall_1: 0.7418 - val_accuracy: 0.7953 - val_auc_1: 0.0000e+00 - val_loss: 0.4652 - val_precision_1: 1.0000 - val_recall_1: 0.7953\n",
      "Epoch 80/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8079 - auc_1: 0.8860 - loss: 0.4095 - precision_1: 0.7450 - recall_1: 0.7414 - val_accuracy: 0.7868 - val_auc_1: 0.0000e+00 - val_loss: 0.4852 - val_precision_1: 1.0000 - val_recall_1: 0.7868\n",
      "Epoch 81/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8140 - auc_1: 0.8901 - loss: 0.4022 - precision_1: 0.7579 - recall_1: 0.7402 - val_accuracy: 0.7989 - val_auc_1: 0.0000e+00 - val_loss: 0.4593 - val_precision_1: 1.0000 - val_recall_1: 0.7989\n",
      "Epoch 82/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8079 - auc_1: 0.8861 - loss: 0.4087 - precision_1: 0.7485 - recall_1: 0.7346 - val_accuracy: 0.7977 - val_auc_1: 0.0000e+00 - val_loss: 0.4566 - val_precision_1: 1.0000 - val_recall_1: 0.7977\n",
      "Epoch 83/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8130 - auc_1: 0.8898 - loss: 0.4031 - precision_1: 0.7561 - recall_1: 0.7402 - val_accuracy: 0.7868 - val_auc_1: 0.0000e+00 - val_loss: 0.4749 - val_precision_1: 1.0000 - val_recall_1: 0.7868\n",
      "Epoch 84/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8147 - auc_1: 0.8888 - loss: 0.4052 - precision_1: 0.7559 - recall_1: 0.7471 - val_accuracy: 0.8007 - val_auc_1: 0.0000e+00 - val_loss: 0.4650 - val_precision_1: 1.0000 - val_recall_1: 0.8007\n",
      "Epoch 85/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8115 - auc_1: 0.8889 - loss: 0.4049 - precision_1: 0.7521 - recall_1: 0.7418 - val_accuracy: 0.7935 - val_auc_1: 0.0000e+00 - val_loss: 0.4764 - val_precision_1: 1.0000 - val_recall_1: 0.7935\n",
      "Epoch 86/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8161 - auc_1: 0.8915 - loss: 0.4013 - precision_1: 0.7591 - recall_1: 0.7463 - val_accuracy: 0.7947 - val_auc_1: 0.0000e+00 - val_loss: 0.4697 - val_precision_1: 1.0000 - val_recall_1: 0.7947\n",
      "Epoch 87/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8088 - auc_1: 0.8896 - loss: 0.4033 - precision_1: 0.7481 - recall_1: 0.7390 - val_accuracy: 0.7862 - val_auc_1: 0.0000e+00 - val_loss: 0.4743 - val_precision_1: 1.0000 - val_recall_1: 0.7862\n",
      "Epoch 88/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8114 - auc_1: 0.8913 - loss: 0.3997 - precision_1: 0.7527 - recall_1: 0.7402 - val_accuracy: 0.7977 - val_auc_1: 0.0000e+00 - val_loss: 0.4761 - val_precision_1: 1.0000 - val_recall_1: 0.7977\n",
      "Epoch 89/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8137 - auc_1: 0.8902 - loss: 0.4014 - precision_1: 0.7527 - recall_1: 0.7491 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4883 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 90/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8173 - auc_1: 0.8924 - loss: 0.3987 - precision_1: 0.7616 - recall_1: 0.7463 - val_accuracy: 0.8104 - val_auc_1: 0.0000e+00 - val_loss: 0.4408 - val_precision_1: 1.0000 - val_recall_1: 0.8104\n",
      "Epoch 91/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8170 - auc_1: 0.8937 - loss: 0.3968 - precision_1: 0.7595 - recall_1: 0.7491 - val_accuracy: 0.7905 - val_auc_1: 0.0000e+00 - val_loss: 0.4803 - val_precision_1: 1.0000 - val_recall_1: 0.7905\n",
      "Epoch 92/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8105 - auc_1: 0.8878 - loss: 0.4065 - precision_1: 0.7498 - recall_1: 0.7422 - val_accuracy: 0.7965 - val_auc_1: 0.0000e+00 - val_loss: 0.4801 - val_precision_1: 1.0000 - val_recall_1: 0.7965\n",
      "Epoch 93/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8162 - auc_1: 0.8911 - loss: 0.4010 - precision_1: 0.7554 - recall_1: 0.7539 - val_accuracy: 0.8013 - val_auc_1: 0.0000e+00 - val_loss: 0.4659 - val_precision_1: 1.0000 - val_recall_1: 0.8013\n",
      "Epoch 94/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8112 - auc_1: 0.8893 - loss: 0.4044 - precision_1: 0.7495 - recall_1: 0.7459 - val_accuracy: 0.8068 - val_auc_1: 0.0000e+00 - val_loss: 0.4533 - val_precision_1: 1.0000 - val_recall_1: 0.8068\n",
      "Epoch 95/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8129 - auc_1: 0.8916 - loss: 0.4010 - precision_1: 0.7551 - recall_1: 0.7414 - val_accuracy: 0.7935 - val_auc_1: 0.0000e+00 - val_loss: 0.4666 - val_precision_1: 1.0000 - val_recall_1: 0.7935\n",
      "Epoch 96/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8140 - auc_1: 0.8913 - loss: 0.4012 - precision_1: 0.7540 - recall_1: 0.7479 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4840 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 97/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8185 - auc_1: 0.8949 - loss: 0.3938 - precision_1: 0.7607 - recall_1: 0.7527 - val_accuracy: 0.8074 - val_auc_1: 0.0000e+00 - val_loss: 0.4616 - val_precision_1: 1.0000 - val_recall_1: 0.8074\n",
      "Epoch 98/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8174 - auc_1: 0.8930 - loss: 0.3972 - precision_1: 0.7571 - recall_1: 0.7555 - val_accuracy: 0.8037 - val_auc_1: 0.0000e+00 - val_loss: 0.4639 - val_precision_1: 1.0000 - val_recall_1: 0.8037\n",
      "Epoch 99/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8144 - auc_1: 0.8925 - loss: 0.3982 - precision_1: 0.7549 - recall_1: 0.7479 - val_accuracy: 0.8019 - val_auc_1: 0.0000e+00 - val_loss: 0.4748 - val_precision_1: 1.0000 - val_recall_1: 0.8019\n",
      "Epoch 100/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8097 - auc_1: 0.8902 - loss: 0.4025 - precision_1: 0.7501 - recall_1: 0.7386 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4839 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Baseline model training completed\n",
      "Baseline model performance\n",
      "============================================================\n",
      "Accuracy: 0.7658\n",
      "Precision: 0.5493\n",
      "Recall: 0.6551\n",
      "F1-Score: 0.5976\n",
      "ROC-AUC: 0.8276\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.87      0.81      0.83      1035\n",
      "       Churn       0.55      0.66      0.60       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.73      0.72      1409\n",
      "weighted avg       0.78      0.77      0.77      1409\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[834 201]\n",
      " [129 245]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:34:38.327250Z",
     "start_time": "2025-12-12T00:31:50.962210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#hyperparameter tuning\n",
    "print(\"Step 4: Hyperparameter tuning\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#define configs to test\n",
    "configs = [\n",
    "    {'name': 'Config 1: Small Network', 'layers': [32, 16], 'dropout': 0.2, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 2: Medium Network', 'layers': [64, 32], 'dropout': 0.3, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 3: Large Network', 'layers': [128, 64, 32], 'dropout': 0.3, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 4: Deep Network', 'layers': [64, 64, 32, 16], 'dropout': 0.4, 'batch_size': 64, 'lr': 0.0005},\n",
    "    {'name': 'Config 5: Wide Network', 'layers': [256, 128], 'dropout': 0.4, 'batch_size': 64, 'lr': 0.001},\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal configurations to test: {len(configs)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_score = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "best_history =None\n",
    "config_results = []\n",
    "\n",
    "for idx, config in enumerate(configs,1):\n",
    "    print(f\"\\n[{idx}/{len(configs)}] Testing: {config['name']}\")\n",
    "    print(f\"Layers: {config['layers']}\")\n",
    "    print(f\"Dropout: {config['dropout']}\")\n",
    "    print(f\"Batch Size: {config['batch_size']}\")\n",
    "    print(f\"Learning Rate: {config['lr']}\")\n",
    "\n",
    "    #create model\n",
    "    model = create_nn_model(\n",
    "        hidden_layers=config['layers'],\n",
    "        dropout_rate=config['dropout'],\n",
    "        learning_rate=config['lr']\n",
    "    )\n",
    "\n",
    "    #define callbacks\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=0.00001,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=config['batch_size'],\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #evaluate on validation set\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_auc = model.evaluate(\n",
    "        X_train[int(0.8*len(X_train)):],\n",
    "        y_train[int(0.8*len(y_train)):],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calculate F1 score on validation set\n",
    "    val_pred_proba = model.predict(X_train[int(0.8*len(X_train)):], verbose=0).flatten()\n",
    "    val_pred = (val_pred_proba > 0.5).astype(int)\n",
    "    val_f1 = f1_score(y_train[int(0.8*len(y_train)):], val_pred)\n",
    "\n",
    "    print(f\"Validation F1-Score: {val_f1:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
    "\n",
    "    # Store results\n",
    "    config_results.append({\n",
    "        'config': config['name'],\n",
    "        'f1_score': val_f1,\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'auc': val_auc\n",
    "    })\n",
    "    # Check if this is the best model\n",
    "    if val_f1 > best_score:\n",
    "        best_score = val_f1\n",
    "        best_config = config\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        print(f\"New best model. F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"Hyperparameter tuning results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame(config_results).sort_values('f1_score', ascending=False)\n",
    "print(\"\\nAll Configurations (sorted by F1-Score):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"Best configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Configuration: {best_config['name']}\")\n",
    "print(f\"Layers: {best_config['layers']}\")\n",
    "print(f\"Dropout: {best_config['dropout']}\")\n",
    "print(f\"Batch Size: {best_config['batch_size']}\")\n",
    "print(f\"Learning Rate: {best_config['lr']}\")\n",
    "print(f\"Best Validation F1-Score: {best_score:.4f}\")"
   ],
   "id": "229536555e70f89c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Hyperparameter tuning\n",
      "============================================================\n",
      "\n",
      "Total configurations to test: 5\n",
      "============================================================\n",
      "\n",
      "[1/5] Testing: Config 1: Small Network\n",
      "Layers: [32, 16]\n",
      "Dropout: 0.2\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8528\n",
      "Validation Loss: 0.5494\n",
      "Epochs trained: 80\n",
      "New best model. F1-Score: 0.8528\n",
      "\n",
      "[2/5] Testing: Config 2: Medium Network\n",
      "Layers: [64, 32]\n",
      "Dropout: 0.3\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8867\n",
      "Validation Loss: 0.4814\n",
      "Epochs trained: 48\n",
      "New best model. F1-Score: 0.8867\n",
      "\n",
      "[3/5] Testing: Config 3: Large Network\n",
      "Layers: [128, 64, 32]\n",
      "Dropout: 0.3\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8727\n",
      "Validation Loss: 0.5013\n",
      "Epochs trained: 18\n",
      "\n",
      "[4/5] Testing: Config 4: Deep Network\n",
      "Layers: [64, 64, 32, 16]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.0005\n",
      "Validation F1-Score: 0.8500\n",
      "Validation Loss: 0.6017\n",
      "Epochs trained: 36\n",
      "\n",
      "[5/5] Testing: Config 5: Wide Network\n",
      "Layers: [256, 128]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.9155\n",
      "Validation Loss: 0.3786\n",
      "Epochs trained: 79\n",
      "New best model. F1-Score: 0.9155\n",
      "Hyperparameter tuning results\n",
      "============================================================\n",
      "\n",
      "All Configurations (sorted by F1-Score):\n",
      "                  config  f1_score     loss  accuracy  auc\n",
      "  Config 5: Wide Network  0.915521 0.378597  0.844203  0.0\n",
      "Config 2: Medium Network  0.886723 0.481410  0.796498  0.0\n",
      " Config 3: Large Network  0.872703 0.501312  0.774155  0.0\n",
      " Config 1: Small Network  0.852788 0.549439  0.743357  0.0\n",
      "  Config 4: Deep Network  0.850000 0.601658  0.739130  0.0\n",
      "Best configuration\n",
      "============================================================\n",
      "Configuration: Config 5: Wide Network\n",
      "Layers: [256, 128]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.001\n",
      "Best Validation F1-Score: 0.9155\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59e1e5bbcb17ff3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
