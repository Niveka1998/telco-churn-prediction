{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-11T23:52:23.551206Z",
     "start_time": "2025-12-11T23:52:23.538969Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "from keras import layers, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.makedirs('results/figures', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T23:56:58.701866Z",
     "start_time": "2025-12-11T23:56:58.692644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#neural network classifier\n",
    "print(\"Neural network classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#load preprocessed data\n",
    "print(\"Step 1: Loading preprocesses data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('models/preprocessed_data.pkl','rb') as f:\n",
    "    preprocessed_data= pickle.load(f)\n",
    "\n",
    "feature_names = preprocessed_data['feature_names']\n",
    "X_train = preprocessed_data['X_train']\n",
    "X_test = preprocessed_data['X_test']\n",
    "y_train = preprocessed_data['y_train']\n",
    "y_test= preprocessed_data['y_test']\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"Training data samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Class distribution (train): {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution (test): {np.bincount(y_test)}\")\n",
    "\n",
    "input_dimension = X_train.shape[1]\n",
    "print(f\"\\nInput dimension for neural network: {input_dimension}\")\n"
   ],
   "id": "2831dd684aa4d2f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classifier\n",
      "============================================================\n",
      "Step 1: Loading preprocesses data\n",
      "============================================================\n",
      "Data loaded successfully.\n",
      "Training data samples: 8278\n",
      "Test samples: 1409\n",
      "Features: 19\n",
      "Class distribution (train): [4139 4139]\n",
      "Class distribution (test): [1035  374]\n",
      "\n",
      "Input dimension for neural network: 19\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:19:36.379026Z",
     "start_time": "2025-12-12T00:19:36.368636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#define neural network architecture\n",
    "print(\"Step 2: Neural network architecture design\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def create_nn_model(hidden_layers=[64,32], dropout_rate=0.3, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    create a nural network model with specified architecture\n",
    "    Parameters:\n",
    "    :param hidden_layers: list of integers [neurons in each hidden layer]\n",
    "    :param dropout_rate: dropout rate for regularization\n",
    "    :param learning_rate: learning rate for optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential(name='ChurnPredictionNN')\n",
    "\n",
    "    #Input layer\n",
    "    model.add(Dense(hidden_layers[0], activation='relu', input_dim=input_dimension))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    #hidden layers\n",
    "    for i, units in enumerate(hidden_layers[1:], start=2):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "    #compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                 keras.metrics.Precision(),\n",
    "                 keras.metrics.Recall(),\n",
    "                 keras.metrics.AUC()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "1be4286dfd91807a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Neural network architecture design\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:21:39.193231Z",
     "start_time": "2025-12-12T00:20:32.973317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#baseline model\n",
    "print(\"Step 3: Baseline neural network model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Architecture: [64, 32] neurons, dropout=0.3, learning_rate=0.001\")\n",
    "\n",
    "#create baseline model\n",
    "bs_model = create_nn_model(hidden_layers=[64,32], dropout_rate=0.3, learning_rate=0.001)\n",
    "\n",
    "#display model architecture\n",
    "print(\"\\nModel architecture:\")\n",
    "bs_model.summary()\n",
    "\n",
    "#define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#train baseline\n",
    "print(\"\\nTraining baseline model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_baseline = bs_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\nBaseline model training completed\")\n",
    "\n",
    "#make prediction\n",
    "y_pred_prob_baseline = bs_model.predict(X_test, verbose=0).flatten()\n",
    "y_pred_baseline = (y_pred_prob_baseline > 0.5).astype(int)\n",
    "\n",
    "#evaluate baseline model\n",
    "print(\"Baseline model performance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "bs_accuracy= accuracy_score(y_test, y_pred_baseline) #percentage of correct predictions\n",
    "\n",
    "bs_precision = precision_score(y_test, y_pred_baseline) #Of all predicted \"Churn\" customers, how many actually churned?\n",
    "\n",
    "bs_recall = recall_score(y_test, y_pred_baseline)#Of all actual churners, how many did the model detect?\n",
    "\n",
    "bs_f1 = f1_score(y_test, y_pred_baseline) #Harmonic mean of Precision & Recall\n",
    "\n",
    "bs_roc_auc = roc_auc_score(y_test, y_pred_prob_baseline)\n",
    "#Measures overall ranking ability of the model: [0.5 - random guessing, 1- perfect]\n",
    "\n",
    "print(f\"Accuracy: {bs_accuracy:.4f}\")\n",
    "print(f\"Precision: {bs_precision:.4f}\")\n",
    "print(f\"Recall: {bs_recall:.4f}\")\n",
    "print(f\"F1-Score: {bs_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {bs_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_baseline, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(cm)\n",
    "\n"
   ],
   "id": "9afb416ecee67b14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Baseline neural network model\n",
      "============================================================\n",
      "Architecture: [64, 32] neurons, dropout=0.3, learning_rate=0.001\n",
      "\n",
      "Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"ChurnPredictionNN\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ChurnPredictionNN\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m1,280\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001B[38;5;33mDense\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3,777\u001B[0m (14.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,585\u001B[0m (14.00 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,585</span> (14.00 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m192\u001B[0m (768.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline model\n",
      "============================================================\n",
      "Epoch 1/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.6927 - auc_1: 0.7483 - loss: 0.6192 - precision_1: 0.5776 - recall_1: 0.6714 - val_accuracy: 0.7391 - val_auc_1: 0.0000e+00 - val_loss: 0.5817 - val_precision_1: 1.0000 - val_recall_1: 0.7391\n",
      "Epoch 2/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7452 - auc_1: 0.8103 - loss: 0.5204 - precision_1: 0.6582 - recall_1: 0.6669 - val_accuracy: 0.7434 - val_auc_1: 0.0000e+00 - val_loss: 0.5612 - val_precision_1: 1.0000 - val_recall_1: 0.7434\n",
      "Epoch 3/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7496 - auc_1: 0.8177 - loss: 0.5077 - precision_1: 0.6672 - recall_1: 0.6629 - val_accuracy: 0.7560 - val_auc_1: 0.0000e+00 - val_loss: 0.5523 - val_precision_1: 1.0000 - val_recall_1: 0.7560\n",
      "Epoch 4/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7563 - auc_1: 0.8286 - loss: 0.4905 - precision_1: 0.6773 - recall_1: 0.6685 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5466 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 5/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7625 - auc_1: 0.8349 - loss: 0.4823 - precision_1: 0.6859 - recall_1: 0.6762 - val_accuracy: 0.7609 - val_auc_1: 0.0000e+00 - val_loss: 0.5377 - val_precision_1: 1.0000 - val_recall_1: 0.7609\n",
      "Epoch 6/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7691 - auc_1: 0.8410 - loss: 0.4731 - precision_1: 0.6950 - recall_1: 0.6847 - val_accuracy: 0.7446 - val_auc_1: 0.0000e+00 - val_loss: 0.5601 - val_precision_1: 1.0000 - val_recall_1: 0.7446\n",
      "Epoch 7/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7676 - auc_1: 0.8396 - loss: 0.4753 - precision_1: 0.6955 - recall_1: 0.6762 - val_accuracy: 0.7428 - val_auc_1: 0.0000e+00 - val_loss: 0.5513 - val_precision_1: 1.0000 - val_recall_1: 0.7428\n",
      "Epoch 8/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7724 - auc_1: 0.8428 - loss: 0.4714 - precision_1: 0.7015 - recall_1: 0.6843 - val_accuracy: 0.7512 - val_auc_1: 0.0000e+00 - val_loss: 0.5446 - val_precision_1: 1.0000 - val_recall_1: 0.7512\n",
      "Epoch 9/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7762 - auc_1: 0.8475 - loss: 0.4652 - precision_1: 0.7054 - recall_1: 0.6923 - val_accuracy: 0.7518 - val_auc_1: 0.0000e+00 - val_loss: 0.5428 - val_precision_1: 1.0000 - val_recall_1: 0.7518\n",
      "Epoch 10/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7759 - auc_1: 0.8481 - loss: 0.4651 - precision_1: 0.7056 - recall_1: 0.6903 - val_accuracy: 0.7379 - val_auc_1: 0.0000e+00 - val_loss: 0.5591 - val_precision_1: 1.0000 - val_recall_1: 0.7379\n",
      "Epoch 11/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7724 - auc_1: 0.8476 - loss: 0.4661 - precision_1: 0.7033 - recall_1: 0.6798 - val_accuracy: 0.7530 - val_auc_1: 0.0000e+00 - val_loss: 0.5431 - val_precision_1: 1.0000 - val_recall_1: 0.7530\n",
      "Epoch 12/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7762 - auc_1: 0.8476 - loss: 0.4649 - precision_1: 0.7024 - recall_1: 0.6996 - val_accuracy: 0.7560 - val_auc_1: 0.0000e+00 - val_loss: 0.5469 - val_precision_1: 1.0000 - val_recall_1: 0.7560\n",
      "Epoch 13/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7810 - auc_1: 0.8548 - loss: 0.4551 - precision_1: 0.7133 - recall_1: 0.6955 - val_accuracy: 0.7536 - val_auc_1: 0.0000e+00 - val_loss: 0.5524 - val_precision_1: 1.0000 - val_recall_1: 0.7536\n",
      "Epoch 14/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7794 - auc_1: 0.8522 - loss: 0.4596 - precision_1: 0.7099 - recall_1: 0.6959 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5458 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 15/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7800 - auc_1: 0.8555 - loss: 0.4540 - precision_1: 0.7099 - recall_1: 0.6988 - val_accuracy: 0.7591 - val_auc_1: 0.0000e+00 - val_loss: 0.5397 - val_precision_1: 1.0000 - val_recall_1: 0.7591\n",
      "Epoch 16/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7831 - auc_1: 0.8553 - loss: 0.4547 - precision_1: 0.7164 - recall_1: 0.6979 - val_accuracy: 0.7603 - val_auc_1: 0.0000e+00 - val_loss: 0.5349 - val_precision_1: 1.0000 - val_recall_1: 0.7603\n",
      "Epoch 17/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7828 - auc_1: 0.8532 - loss: 0.4576 - precision_1: 0.7146 - recall_1: 0.7008 - val_accuracy: 0.7482 - val_auc_1: 0.0000e+00 - val_loss: 0.5451 - val_precision_1: 1.0000 - val_recall_1: 0.7482\n",
      "Epoch 18/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7798 - auc_1: 0.8574 - loss: 0.4520 - precision_1: 0.7140 - recall_1: 0.6887 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5319 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 19/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7791 - auc_1: 0.8579 - loss: 0.4517 - precision_1: 0.7120 - recall_1: 0.6899 - val_accuracy: 0.7482 - val_auc_1: 0.0000e+00 - val_loss: 0.5449 - val_precision_1: 1.0000 - val_recall_1: 0.7482\n",
      "Epoch 20/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7853 - auc_1: 0.8598 - loss: 0.4486 - precision_1: 0.7172 - recall_1: 0.7056 - val_accuracy: 0.7530 - val_auc_1: 0.0000e+00 - val_loss: 0.5370 - val_precision_1: 1.0000 - val_recall_1: 0.7530\n",
      "Epoch 21/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7848 - auc_1: 0.8599 - loss: 0.4495 - precision_1: 0.7173 - recall_1: 0.7032 - val_accuracy: 0.7476 - val_auc_1: 0.0000e+00 - val_loss: 0.5478 - val_precision_1: 1.0000 - val_recall_1: 0.7476\n",
      "Epoch 22/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7887 - auc_1: 0.8635 - loss: 0.4442 - precision_1: 0.7262 - recall_1: 0.7008 - val_accuracy: 0.7554 - val_auc_1: 0.0000e+00 - val_loss: 0.5372 - val_precision_1: 1.0000 - val_recall_1: 0.7554\n",
      "Epoch 23/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7871 - auc_1: 0.8643 - loss: 0.4416 - precision_1: 0.7203 - recall_1: 0.7064 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5221 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 24/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7878 - auc_1: 0.8608 - loss: 0.4485 - precision_1: 0.7248 - recall_1: 0.7000 - val_accuracy: 0.7591 - val_auc_1: 0.0000e+00 - val_loss: 0.5280 - val_precision_1: 1.0000 - val_recall_1: 0.7591\n",
      "Epoch 25/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7912 - auc_1: 0.8646 - loss: 0.4423 - precision_1: 0.7265 - recall_1: 0.7104 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5321 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 26/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7896 - auc_1: 0.8632 - loss: 0.4442 - precision_1: 0.7280 - recall_1: 0.7008 - val_accuracy: 0.7579 - val_auc_1: 0.0000e+00 - val_loss: 0.5325 - val_precision_1: 1.0000 - val_recall_1: 0.7579\n",
      "Epoch 27/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7948 - auc_1: 0.8665 - loss: 0.4391 - precision_1: 0.7363 - recall_1: 0.7052 - val_accuracy: 0.7585 - val_auc_1: 0.0000e+00 - val_loss: 0.5367 - val_precision_1: 1.0000 - val_recall_1: 0.7585\n",
      "Epoch 28/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7892 - auc_1: 0.8626 - loss: 0.4456 - precision_1: 0.7249 - recall_1: 0.7056 - val_accuracy: 0.7687 - val_auc_1: 0.0000e+00 - val_loss: 0.5216 - val_precision_1: 1.0000 - val_recall_1: 0.7687\n",
      "Epoch 29/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7898 - auc_1: 0.8637 - loss: 0.4436 - precision_1: 0.7238 - recall_1: 0.7104 - val_accuracy: 0.7554 - val_auc_1: 0.0000e+00 - val_loss: 0.5242 - val_precision_1: 1.0000 - val_recall_1: 0.7554\n",
      "Epoch 30/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7949 - auc_1: 0.8636 - loss: 0.4438 - precision_1: 0.7362 - recall_1: 0.7060 - val_accuracy: 0.7615 - val_auc_1: 0.0000e+00 - val_loss: 0.5230 - val_precision_1: 1.0000 - val_recall_1: 0.7615\n",
      "Epoch 31/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7916 - auc_1: 0.8668 - loss: 0.4392 - precision_1: 0.7263 - recall_1: 0.7128 - val_accuracy: 0.7585 - val_auc_1: 0.0000e+00 - val_loss: 0.5287 - val_precision_1: 1.0000 - val_recall_1: 0.7585\n",
      "Epoch 32/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7933 - auc_1: 0.8666 - loss: 0.4394 - precision_1: 0.7313 - recall_1: 0.7092 - val_accuracy: 0.7627 - val_auc_1: 0.0000e+00 - val_loss: 0.5239 - val_precision_1: 1.0000 - val_recall_1: 0.7627\n",
      "Epoch 33/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7912 - auc_1: 0.8685 - loss: 0.4363 - precision_1: 0.7262 - recall_1: 0.7112 - val_accuracy: 0.7621 - val_auc_1: 0.0000e+00 - val_loss: 0.5288 - val_precision_1: 1.0000 - val_recall_1: 0.7621\n",
      "Epoch 34/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7933 - auc_1: 0.8693 - loss: 0.4359 - precision_1: 0.7281 - recall_1: 0.7161 - val_accuracy: 0.7754 - val_auc_1: 0.0000e+00 - val_loss: 0.5157 - val_precision_1: 1.0000 - val_recall_1: 0.7754\n",
      "Epoch 35/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7940 - auc_1: 0.8669 - loss: 0.4390 - precision_1: 0.7298 - recall_1: 0.7157 - val_accuracy: 0.7723 - val_auc_1: 0.0000e+00 - val_loss: 0.5245 - val_precision_1: 1.0000 - val_recall_1: 0.7723\n",
      "Epoch 36/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7990 - auc_1: 0.8719 - loss: 0.4315 - precision_1: 0.7349 - recall_1: 0.7257 - val_accuracy: 0.7705 - val_auc_1: 0.0000e+00 - val_loss: 0.5134 - val_precision_1: 1.0000 - val_recall_1: 0.7705\n",
      "Epoch 37/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.7955 - auc_1: 0.8686 - loss: 0.4369 - precision_1: 0.7314 - recall_1: 0.7185 - val_accuracy: 0.7717 - val_auc_1: 0.0000e+00 - val_loss: 0.5202 - val_precision_1: 1.0000 - val_recall_1: 0.7717\n",
      "Epoch 38/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7937 - auc_1: 0.8692 - loss: 0.4360 - precision_1: 0.7273 - recall_1: 0.7197 - val_accuracy: 0.7693 - val_auc_1: 0.0000e+00 - val_loss: 0.5188 - val_precision_1: 1.0000 - val_recall_1: 0.7693\n",
      "Epoch 39/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7951 - auc_1: 0.8727 - loss: 0.4296 - precision_1: 0.7338 - recall_1: 0.7116 - val_accuracy: 0.7681 - val_auc_1: 0.0000e+00 - val_loss: 0.5105 - val_precision_1: 1.0000 - val_recall_1: 0.7681\n",
      "Epoch 40/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7949 - auc_1: 0.8695 - loss: 0.4337 - precision_1: 0.7288 - recall_1: 0.7217 - val_accuracy: 0.7572 - val_auc_1: 0.0000e+00 - val_loss: 0.5264 - val_precision_1: 1.0000 - val_recall_1: 0.7572\n",
      "Epoch 41/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8013 - auc_1: 0.8706 - loss: 0.4342 - precision_1: 0.7406 - recall_1: 0.7233 - val_accuracy: 0.7657 - val_auc_1: 0.0000e+00 - val_loss: 0.5170 - val_precision_1: 1.0000 - val_recall_1: 0.7657\n",
      "Epoch 42/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7981 - auc_1: 0.8730 - loss: 0.4298 - precision_1: 0.7346 - recall_1: 0.7225 - val_accuracy: 0.7729 - val_auc_1: 0.0000e+00 - val_loss: 0.5080 - val_precision_1: 1.0000 - val_recall_1: 0.7729\n",
      "Epoch 43/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8023 - auc_1: 0.8775 - loss: 0.4241 - precision_1: 0.7414 - recall_1: 0.7261 - val_accuracy: 0.7772 - val_auc_1: 0.0000e+00 - val_loss: 0.5011 - val_precision_1: 1.0000 - val_recall_1: 0.7772\n",
      "Epoch 44/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7984 - auc_1: 0.8730 - loss: 0.4289 - precision_1: 0.7339 - recall_1: 0.7253 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4951 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 45/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7982 - auc_1: 0.8749 - loss: 0.4268 - precision_1: 0.7359 - recall_1: 0.7205 - val_accuracy: 0.7742 - val_auc_1: 0.0000e+00 - val_loss: 0.5033 - val_precision_1: 1.0000 - val_recall_1: 0.7742\n",
      "Epoch 46/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7993 - auc_1: 0.8742 - loss: 0.4279 - precision_1: 0.7346 - recall_1: 0.7277 - val_accuracy: 0.7802 - val_auc_1: 0.0000e+00 - val_loss: 0.4984 - val_precision_1: 1.0000 - val_recall_1: 0.7802\n",
      "Epoch 47/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8001 - auc_1: 0.8781 - loss: 0.4217 - precision_1: 0.7364 - recall_1: 0.7269 - val_accuracy: 0.7760 - val_auc_1: 0.0000e+00 - val_loss: 0.4965 - val_precision_1: 1.0000 - val_recall_1: 0.7760\n",
      "Epoch 48/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8014 - auc_1: 0.8765 - loss: 0.4245 - precision_1: 0.7384 - recall_1: 0.7286 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4873 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 49/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7998 - auc_1: 0.8783 - loss: 0.4215 - precision_1: 0.7362 - recall_1: 0.7261 - val_accuracy: 0.7844 - val_auc_1: 0.0000e+00 - val_loss: 0.4870 - val_precision_1: 1.0000 - val_recall_1: 0.7844\n",
      "Epoch 50/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.7987 - auc_1: 0.8763 - loss: 0.4244 - precision_1: 0.7388 - recall_1: 0.7165 - val_accuracy: 0.7736 - val_auc_1: 0.0000e+00 - val_loss: 0.5033 - val_precision_1: 1.0000 - val_recall_1: 0.7736\n",
      "Epoch 51/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8038 - auc_1: 0.8784 - loss: 0.4219 - precision_1: 0.7442 - recall_1: 0.7265 - val_accuracy: 0.7699 - val_auc_1: 0.0000e+00 - val_loss: 0.5148 - val_precision_1: 1.0000 - val_recall_1: 0.7699\n",
      "Epoch 52/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8020 - auc_1: 0.8752 - loss: 0.4264 - precision_1: 0.7419 - recall_1: 0.7237 - val_accuracy: 0.7681 - val_auc_1: 0.0000e+00 - val_loss: 0.5001 - val_precision_1: 1.0000 - val_recall_1: 0.7681\n",
      "Epoch 53/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8023 - auc_1: 0.8812 - loss: 0.4171 - precision_1: 0.7416 - recall_1: 0.7257 - val_accuracy: 0.7748 - val_auc_1: 0.0000e+00 - val_loss: 0.5061 - val_precision_1: 1.0000 - val_recall_1: 0.7748\n",
      "Epoch 54/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8091 - auc_1: 0.8830 - loss: 0.4152 - precision_1: 0.7513 - recall_1: 0.7338 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4962 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 55/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8016 - auc_1: 0.8774 - loss: 0.4231 - precision_1: 0.7391 - recall_1: 0.7277 - val_accuracy: 0.7790 - val_auc_1: 0.0000e+00 - val_loss: 0.4945 - val_precision_1: 1.0000 - val_recall_1: 0.7790\n",
      "Epoch 56/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8053 - auc_1: 0.8801 - loss: 0.4179 - precision_1: 0.7445 - recall_1: 0.7322 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4922 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 57/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8046 - auc_1: 0.8807 - loss: 0.4171 - precision_1: 0.7422 - recall_1: 0.7338 - val_accuracy: 0.7729 - val_auc_1: 0.0000e+00 - val_loss: 0.5050 - val_precision_1: 1.0000 - val_recall_1: 0.7729\n",
      "Epoch 58/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8061 - auc_1: 0.8808 - loss: 0.4177 - precision_1: 0.7456 - recall_1: 0.7330 - val_accuracy: 0.7802 - val_auc_1: 0.0000e+00 - val_loss: 0.4946 - val_precision_1: 1.0000 - val_recall_1: 0.7802\n",
      "Epoch 59/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8019 - auc_1: 0.8777 - loss: 0.4221 - precision_1: 0.7401 - recall_1: 0.7269 - val_accuracy: 0.7965 - val_auc_1: 0.0000e+00 - val_loss: 0.4830 - val_precision_1: 1.0000 - val_recall_1: 0.7965\n",
      "Epoch 60/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8072 - auc_1: 0.8824 - loss: 0.4155 - precision_1: 0.7449 - recall_1: 0.7386 - val_accuracy: 0.7826 - val_auc_1: 0.0000e+00 - val_loss: 0.4944 - val_precision_1: 1.0000 - val_recall_1: 0.7826\n",
      "Epoch 61/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8063 - auc_1: 0.8797 - loss: 0.4191 - precision_1: 0.7443 - recall_1: 0.7362 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4958 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 62/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8085 - auc_1: 0.8815 - loss: 0.4168 - precision_1: 0.7516 - recall_1: 0.7310 - val_accuracy: 0.7796 - val_auc_1: 0.0000e+00 - val_loss: 0.4926 - val_precision_1: 1.0000 - val_recall_1: 0.7796\n",
      "Epoch 63/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8097 - auc_1: 0.8845 - loss: 0.4125 - precision_1: 0.7481 - recall_1: 0.7427 - val_accuracy: 0.7874 - val_auc_1: 0.0000e+00 - val_loss: 0.4832 - val_precision_1: 1.0000 - val_recall_1: 0.7874\n",
      "Epoch 64/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8059 - auc_1: 0.8840 - loss: 0.4115 - precision_1: 0.7435 - recall_1: 0.7366 - val_accuracy: 0.7814 - val_auc_1: 0.0000e+00 - val_loss: 0.4890 - val_precision_1: 1.0000 - val_recall_1: 0.7814\n",
      "Epoch 65/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8032 - auc_1: 0.8809 - loss: 0.4183 - precision_1: 0.7400 - recall_1: 0.7326 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4738 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 66/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8102 - auc_1: 0.8867 - loss: 0.4077 - precision_1: 0.7482 - recall_1: 0.7443 - val_accuracy: 0.7941 - val_auc_1: 0.0000e+00 - val_loss: 0.4787 - val_precision_1: 1.0000 - val_recall_1: 0.7941\n",
      "Epoch 67/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8058 - auc_1: 0.8830 - loss: 0.4131 - precision_1: 0.7416 - recall_1: 0.7398 - val_accuracy: 0.7814 - val_auc_1: 0.0000e+00 - val_loss: 0.4858 - val_precision_1: 1.0000 - val_recall_1: 0.7814\n",
      "Epoch 68/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8120 - auc_1: 0.8867 - loss: 0.4094 - precision_1: 0.7558 - recall_1: 0.7366 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4808 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 69/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8137 - auc_1: 0.8866 - loss: 0.4092 - precision_1: 0.7544 - recall_1: 0.7459 - val_accuracy: 0.7862 - val_auc_1: 0.0000e+00 - val_loss: 0.4848 - val_precision_1: 1.0000 - val_recall_1: 0.7862\n",
      "Epoch 70/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8129 - auc_1: 0.8872 - loss: 0.4086 - precision_1: 0.7539 - recall_1: 0.7439 - val_accuracy: 0.7856 - val_auc_1: 0.0000e+00 - val_loss: 0.4847 - val_precision_1: 1.0000 - val_recall_1: 0.7856\n",
      "Epoch 71/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8126 - auc_1: 0.8860 - loss: 0.4100 - precision_1: 0.7518 - recall_1: 0.7467 - val_accuracy: 0.7880 - val_auc_1: 0.0000e+00 - val_loss: 0.4752 - val_precision_1: 1.0000 - val_recall_1: 0.7880\n",
      "Epoch 72/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8096 - auc_1: 0.8851 - loss: 0.4117 - precision_1: 0.7506 - recall_1: 0.7370 - val_accuracy: 0.7874 - val_auc_1: 0.0000e+00 - val_loss: 0.4754 - val_precision_1: 1.0000 - val_recall_1: 0.7874\n",
      "Epoch 73/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8109 - auc_1: 0.8875 - loss: 0.4061 - precision_1: 0.7493 - recall_1: 0.7451 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4771 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 74/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8066 - auc_1: 0.8837 - loss: 0.4124 - precision_1: 0.7453 - recall_1: 0.7354 - val_accuracy: 0.7886 - val_auc_1: 0.0000e+00 - val_loss: 0.4745 - val_precision_1: 1.0000 - val_recall_1: 0.7886\n",
      "Epoch 75/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8179 - auc_1: 0.8906 - loss: 0.4017 - precision_1: 0.7609 - recall_1: 0.7499 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4672 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 76/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8130 - auc_1: 0.8874 - loss: 0.4073 - precision_1: 0.7578 - recall_1: 0.7370 - val_accuracy: 0.7959 - val_auc_1: 0.0000e+00 - val_loss: 0.4683 - val_precision_1: 1.0000 - val_recall_1: 0.7959\n",
      "Epoch 77/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8094 - auc_1: 0.8851 - loss: 0.4113 - precision_1: 0.7501 - recall_1: 0.7374 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4668 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 78/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8103 - auc_1: 0.8887 - loss: 0.4044 - precision_1: 0.7520 - recall_1: 0.7374 - val_accuracy: 0.7959 - val_auc_1: 0.0000e+00 - val_loss: 0.4698 - val_precision_1: 1.0000 - val_recall_1: 0.7959\n",
      "Epoch 79/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8130 - auc_1: 0.8881 - loss: 0.4062 - precision_1: 0.7552 - recall_1: 0.7418 - val_accuracy: 0.7953 - val_auc_1: 0.0000e+00 - val_loss: 0.4652 - val_precision_1: 1.0000 - val_recall_1: 0.7953\n",
      "Epoch 80/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8079 - auc_1: 0.8860 - loss: 0.4095 - precision_1: 0.7450 - recall_1: 0.7414 - val_accuracy: 0.7868 - val_auc_1: 0.0000e+00 - val_loss: 0.4852 - val_precision_1: 1.0000 - val_recall_1: 0.7868\n",
      "Epoch 81/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8140 - auc_1: 0.8901 - loss: 0.4022 - precision_1: 0.7579 - recall_1: 0.7402 - val_accuracy: 0.7989 - val_auc_1: 0.0000e+00 - val_loss: 0.4593 - val_precision_1: 1.0000 - val_recall_1: 0.7989\n",
      "Epoch 82/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8079 - auc_1: 0.8861 - loss: 0.4087 - precision_1: 0.7485 - recall_1: 0.7346 - val_accuracy: 0.7977 - val_auc_1: 0.0000e+00 - val_loss: 0.4566 - val_precision_1: 1.0000 - val_recall_1: 0.7977\n",
      "Epoch 83/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8130 - auc_1: 0.8898 - loss: 0.4031 - precision_1: 0.7561 - recall_1: 0.7402 - val_accuracy: 0.7868 - val_auc_1: 0.0000e+00 - val_loss: 0.4749 - val_precision_1: 1.0000 - val_recall_1: 0.7868\n",
      "Epoch 84/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8147 - auc_1: 0.8888 - loss: 0.4052 - precision_1: 0.7559 - recall_1: 0.7471 - val_accuracy: 0.8007 - val_auc_1: 0.0000e+00 - val_loss: 0.4650 - val_precision_1: 1.0000 - val_recall_1: 0.8007\n",
      "Epoch 85/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8115 - auc_1: 0.8889 - loss: 0.4049 - precision_1: 0.7521 - recall_1: 0.7418 - val_accuracy: 0.7935 - val_auc_1: 0.0000e+00 - val_loss: 0.4764 - val_precision_1: 1.0000 - val_recall_1: 0.7935\n",
      "Epoch 86/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8161 - auc_1: 0.8915 - loss: 0.4013 - precision_1: 0.7591 - recall_1: 0.7463 - val_accuracy: 0.7947 - val_auc_1: 0.0000e+00 - val_loss: 0.4697 - val_precision_1: 1.0000 - val_recall_1: 0.7947\n",
      "Epoch 87/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8088 - auc_1: 0.8896 - loss: 0.4033 - precision_1: 0.7481 - recall_1: 0.7390 - val_accuracy: 0.7862 - val_auc_1: 0.0000e+00 - val_loss: 0.4743 - val_precision_1: 1.0000 - val_recall_1: 0.7862\n",
      "Epoch 88/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8114 - auc_1: 0.8913 - loss: 0.3997 - precision_1: 0.7527 - recall_1: 0.7402 - val_accuracy: 0.7977 - val_auc_1: 0.0000e+00 - val_loss: 0.4761 - val_precision_1: 1.0000 - val_recall_1: 0.7977\n",
      "Epoch 89/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8137 - auc_1: 0.8902 - loss: 0.4014 - precision_1: 0.7527 - recall_1: 0.7491 - val_accuracy: 0.7808 - val_auc_1: 0.0000e+00 - val_loss: 0.4883 - val_precision_1: 1.0000 - val_recall_1: 0.7808\n",
      "Epoch 90/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8173 - auc_1: 0.8924 - loss: 0.3987 - precision_1: 0.7616 - recall_1: 0.7463 - val_accuracy: 0.8104 - val_auc_1: 0.0000e+00 - val_loss: 0.4408 - val_precision_1: 1.0000 - val_recall_1: 0.8104\n",
      "Epoch 91/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8170 - auc_1: 0.8937 - loss: 0.3968 - precision_1: 0.7595 - recall_1: 0.7491 - val_accuracy: 0.7905 - val_auc_1: 0.0000e+00 - val_loss: 0.4803 - val_precision_1: 1.0000 - val_recall_1: 0.7905\n",
      "Epoch 92/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8105 - auc_1: 0.8878 - loss: 0.4065 - precision_1: 0.7498 - recall_1: 0.7422 - val_accuracy: 0.7965 - val_auc_1: 0.0000e+00 - val_loss: 0.4801 - val_precision_1: 1.0000 - val_recall_1: 0.7965\n",
      "Epoch 93/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8162 - auc_1: 0.8911 - loss: 0.4010 - precision_1: 0.7554 - recall_1: 0.7539 - val_accuracy: 0.8013 - val_auc_1: 0.0000e+00 - val_loss: 0.4659 - val_precision_1: 1.0000 - val_recall_1: 0.8013\n",
      "Epoch 94/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8112 - auc_1: 0.8893 - loss: 0.4044 - precision_1: 0.7495 - recall_1: 0.7459 - val_accuracy: 0.8068 - val_auc_1: 0.0000e+00 - val_loss: 0.4533 - val_precision_1: 1.0000 - val_recall_1: 0.8068\n",
      "Epoch 95/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8129 - auc_1: 0.8916 - loss: 0.4010 - precision_1: 0.7551 - recall_1: 0.7414 - val_accuracy: 0.7935 - val_auc_1: 0.0000e+00 - val_loss: 0.4666 - val_precision_1: 1.0000 - val_recall_1: 0.7935\n",
      "Epoch 96/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8140 - auc_1: 0.8913 - loss: 0.4012 - precision_1: 0.7540 - recall_1: 0.7479 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4840 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Epoch 97/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8185 - auc_1: 0.8949 - loss: 0.3938 - precision_1: 0.7607 - recall_1: 0.7527 - val_accuracy: 0.8074 - val_auc_1: 0.0000e+00 - val_loss: 0.4616 - val_precision_1: 1.0000 - val_recall_1: 0.8074\n",
      "Epoch 98/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8174 - auc_1: 0.8930 - loss: 0.3972 - precision_1: 0.7571 - recall_1: 0.7555 - val_accuracy: 0.8037 - val_auc_1: 0.0000e+00 - val_loss: 0.4639 - val_precision_1: 1.0000 - val_recall_1: 0.8037\n",
      "Epoch 99/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8144 - auc_1: 0.8925 - loss: 0.3982 - precision_1: 0.7549 - recall_1: 0.7479 - val_accuracy: 0.8019 - val_auc_1: 0.0000e+00 - val_loss: 0.4748 - val_precision_1: 1.0000 - val_recall_1: 0.8019\n",
      "Epoch 100/100\n",
      "\u001B[1m207/207\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8097 - auc_1: 0.8902 - loss: 0.4025 - precision_1: 0.7501 - recall_1: 0.7386 - val_accuracy: 0.7911 - val_auc_1: 0.0000e+00 - val_loss: 0.4839 - val_precision_1: 1.0000 - val_recall_1: 0.7911\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Baseline model training completed\n",
      "Baseline model performance\n",
      "============================================================\n",
      "Accuracy: 0.7658\n",
      "Precision: 0.5493\n",
      "Recall: 0.6551\n",
      "F1-Score: 0.5976\n",
      "ROC-AUC: 0.8276\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.87      0.81      0.83      1035\n",
      "       Churn       0.55      0.66      0.60       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.73      0.72      1409\n",
      "weighted avg       0.78      0.77      0.77      1409\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[834 201]\n",
      " [129 245]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T00:34:38.327250Z",
     "start_time": "2025-12-12T00:31:50.962210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#hyperparameter tuning\n",
    "print(\"Step 4: Hyperparameter tuning\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#define configs to test\n",
    "configs = [\n",
    "    {'name': 'Config 1: Small Network', 'layers': [32, 16], 'dropout': 0.2, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 2: Medium Network', 'layers': [64, 32], 'dropout': 0.3, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 3: Large Network', 'layers': [128, 64, 32], 'dropout': 0.3, 'batch_size': 32, 'lr': 0.001},\n",
    "    {'name': 'Config 4: Deep Network', 'layers': [64, 64, 32, 16], 'dropout': 0.4, 'batch_size': 64, 'lr': 0.0005},\n",
    "    {'name': 'Config 5: Wide Network', 'layers': [256, 128], 'dropout': 0.4, 'batch_size': 64, 'lr': 0.001},\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal configurations to test: {len(configs)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_score = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "best_history =None\n",
    "config_results = []\n",
    "\n",
    "for idx, config in enumerate(configs,1):\n",
    "    print(f\"\\n[{idx}/{len(configs)}] Testing: {config['name']}\")\n",
    "    print(f\"Layers: {config['layers']}\")\n",
    "    print(f\"Dropout: {config['dropout']}\")\n",
    "    print(f\"Batch Size: {config['batch_size']}\")\n",
    "    print(f\"Learning Rate: {config['lr']}\")\n",
    "\n",
    "    #create model\n",
    "    model = create_nn_model(\n",
    "        hidden_layers=config['layers'],\n",
    "        dropout_rate=config['dropout'],\n",
    "        learning_rate=config['lr']\n",
    "    )\n",
    "\n",
    "    #define callbacks\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=0.00001,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=config['batch_size'],\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #evaluate on validation set\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_auc = model.evaluate(\n",
    "        X_train[int(0.8*len(X_train)):],\n",
    "        y_train[int(0.8*len(y_train)):],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calculate F1 score on validation set\n",
    "    val_pred_proba = model.predict(X_train[int(0.8*len(X_train)):], verbose=0).flatten()\n",
    "    val_pred = (val_pred_proba > 0.5).astype(int)\n",
    "    val_f1 = f1_score(y_train[int(0.8*len(y_train)):], val_pred)\n",
    "\n",
    "    print(f\"Validation F1-Score: {val_f1:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Epochs trained: {len(history.history['loss'])}\")\n",
    "\n",
    "    # Store results\n",
    "    config_results.append({\n",
    "        'config': config['name'],\n",
    "        'f1_score': val_f1,\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'auc': val_auc\n",
    "    })\n",
    "    # Check if this is the best model\n",
    "    if val_f1 > best_score:\n",
    "        best_score = val_f1\n",
    "        best_config = config\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        print(f\"New best model. F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"Hyperparameter tuning results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame(config_results).sort_values('f1_score', ascending=False)\n",
    "print(\"\\nAll Configurations (sorted by F1-Score):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"Best configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Configuration: {best_config['name']}\")\n",
    "print(f\"Layers: {best_config['layers']}\")\n",
    "print(f\"Dropout: {best_config['dropout']}\")\n",
    "print(f\"Batch Size: {best_config['batch_size']}\")\n",
    "print(f\"Learning Rate: {best_config['lr']}\")\n",
    "print(f\"Best Validation F1-Score: {best_score:.4f}\")"
   ],
   "id": "229536555e70f89c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Hyperparameter tuning\n",
      "============================================================\n",
      "\n",
      "Total configurations to test: 5\n",
      "============================================================\n",
      "\n",
      "[1/5] Testing: Config 1: Small Network\n",
      "Layers: [32, 16]\n",
      "Dropout: 0.2\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8528\n",
      "Validation Loss: 0.5494\n",
      "Epochs trained: 80\n",
      "New best model. F1-Score: 0.8528\n",
      "\n",
      "[2/5] Testing: Config 2: Medium Network\n",
      "Layers: [64, 32]\n",
      "Dropout: 0.3\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8867\n",
      "Validation Loss: 0.4814\n",
      "Epochs trained: 48\n",
      "New best model. F1-Score: 0.8867\n",
      "\n",
      "[3/5] Testing: Config 3: Large Network\n",
      "Layers: [128, 64, 32]\n",
      "Dropout: 0.3\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.8727\n",
      "Validation Loss: 0.5013\n",
      "Epochs trained: 18\n",
      "\n",
      "[4/5] Testing: Config 4: Deep Network\n",
      "Layers: [64, 64, 32, 16]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.0005\n",
      "Validation F1-Score: 0.8500\n",
      "Validation Loss: 0.6017\n",
      "Epochs trained: 36\n",
      "\n",
      "[5/5] Testing: Config 5: Wide Network\n",
      "Layers: [256, 128]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.001\n",
      "Validation F1-Score: 0.9155\n",
      "Validation Loss: 0.3786\n",
      "Epochs trained: 79\n",
      "New best model. F1-Score: 0.9155\n",
      "Hyperparameter tuning results\n",
      "============================================================\n",
      "\n",
      "All Configurations (sorted by F1-Score):\n",
      "                  config  f1_score     loss  accuracy  auc\n",
      "  Config 5: Wide Network  0.915521 0.378597  0.844203  0.0\n",
      "Config 2: Medium Network  0.886723 0.481410  0.796498  0.0\n",
      " Config 3: Large Network  0.872703 0.501312  0.774155  0.0\n",
      " Config 1: Small Network  0.852788 0.549439  0.743357  0.0\n",
      "  Config 4: Deep Network  0.850000 0.601658  0.739130  0.0\n",
      "Best configuration\n",
      "============================================================\n",
      "Configuration: Config 5: Wide Network\n",
      "Layers: [256, 128]\n",
      "Dropout: 0.4\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.001\n",
      "Best Validation F1-Score: 0.9155\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:27:51.398250Z",
     "start_time": "2025-12-12T01:27:03.727071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train optimized model\n",
    "print(\"Step 5: Training final optimized model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#create final model with best config\n",
    "nn_optimized = create_nn_model(\n",
    "    hidden_layers=best_config['layers'],\n",
    "    dropout_rate=best_config['dropout'],\n",
    "    learning_rate=best_config['lr']\n",
    ")\n",
    "\n",
    "#define callbacks for final training\n",
    "early_stop_final = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_final = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'models/neural_network_best.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#train\n",
    "print(\"\\nTraining optimized model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_optimized = nn_optimized.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=best_config['batch_size'],\n",
    "    callbacks=[early_stop_final, reduce_lr_final, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nOptimized model training completed\")\n",
    "print(f\"Total epochs: {len(history_optimized.history['loss'])}\")"
   ],
   "id": "59e1e5bbcb17ff3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Training final optimized model\n",
      "============================================================\n",
      "\n",
      "Training optimized model\n",
      "============================================================\n",
      "Epoch 1/150\n",
      "\u001B[1m 86/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6607 - auc_8: 0.7169 - loss: 0.7483 - precision_8: 0.5328 - recall_8: 0.6713\n",
      "Epoch 1: val_loss improved from None to 0.89233, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 9ms/step - accuracy: 0.7101 - auc_8: 0.7726 - loss: 0.6336 - precision_8: 0.5977 - recall_8: 0.6935 - val_accuracy: 0.2766 - val_auc_8: 0.0000e+00 - val_loss: 0.8923 - val_precision_8: 1.0000 - val_recall_8: 0.2766 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001B[1m 87/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7396 - auc_8: 0.8059 - loss: 0.5419 - precision_8: 0.6427 - recall_8: 0.6654\n",
      "Epoch 2: val_loss improved from 0.89233 to 0.79535, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7463 - auc_8: 0.8149 - loss: 0.5300 - precision_8: 0.6589 - recall_8: 0.6706 - val_accuracy: 0.5097 - val_auc_8: 0.0000e+00 - val_loss: 0.7954 - val_precision_8: 1.0000 - val_recall_8: 0.5097 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001B[1m 86/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7486 - auc_8: 0.8197 - loss: 0.5148 - precision_8: 0.6617 - recall_8: 0.6538\n",
      "Epoch 3: val_loss improved from 0.79535 to 0.61437, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7572 - auc_8: 0.8306 - loss: 0.5003 - precision_8: 0.6779 - recall_8: 0.6714 - val_accuracy: 0.7017 - val_auc_8: 0.0000e+00 - val_loss: 0.6144 - val_precision_8: 1.0000 - val_recall_8: 0.7017 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001B[1m102/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7691 - auc_8: 0.8376 - loss: 0.4796 - precision_8: 0.6930 - recall_8: 0.6769\n",
      "Epoch 4: val_loss improved from 0.61437 to 0.55417, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7717 - auc_8: 0.8415 - loss: 0.4785 - precision_8: 0.7000 - recall_8: 0.6843 - val_accuracy: 0.7434 - val_auc_8: 0.0000e+00 - val_loss: 0.5542 - val_precision_8: 1.0000 - val_recall_8: 0.7434 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7737 - auc_8: 0.8369 - loss: 0.4822 - precision_8: 0.6966 - recall_8: 0.6888\n",
      "Epoch 5: val_loss improved from 0.55417 to 0.50480, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7726 - auc_8: 0.8451 - loss: 0.4706 - precision_8: 0.6990 - recall_8: 0.6911 - val_accuracy: 0.7717 - val_auc_8: 0.0000e+00 - val_loss: 0.5048 - val_precision_8: 1.0000 - val_recall_8: 0.7717 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001B[1m 89/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7675 - auc_8: 0.8443 - loss: 0.4707 - precision_8: 0.6908 - recall_8: 0.6719\n",
      "Epoch 6: val_loss did not improve from 0.50480\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7732 - auc_8: 0.8516 - loss: 0.4602 - precision_8: 0.7008 - recall_8: 0.6895 - val_accuracy: 0.7663 - val_auc_8: 0.0000e+00 - val_loss: 0.5108 - val_precision_8: 1.0000 - val_recall_8: 0.7663 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7864 - auc_8: 0.8543 - loss: 0.4571 - precision_8: 0.7181 - recall_8: 0.6980\n",
      "Epoch 7: val_loss improved from 0.50480 to 0.50339, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7877 - auc_8: 0.8571 - loss: 0.4536 - precision_8: 0.7224 - recall_8: 0.7044 - val_accuracy: 0.7663 - val_auc_8: 0.0000e+00 - val_loss: 0.5034 - val_precision_8: 1.0000 - val_recall_8: 0.7663 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7702 - auc_8: 0.8542 - loss: 0.4570 - precision_8: 0.6912 - recall_8: 0.6849\n",
      "Epoch 8: val_loss did not improve from 0.50339\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7751 - auc_8: 0.8569 - loss: 0.4524 - precision_8: 0.7012 - recall_8: 0.6975 - val_accuracy: 0.7754 - val_auc_8: 0.0000e+00 - val_loss: 0.5036 - val_precision_8: 1.0000 - val_recall_8: 0.7754 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001B[1m 90/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7812 - auc_8: 0.8557 - loss: 0.4549 - precision_8: 0.7097 - recall_8: 0.6914\n",
      "Epoch 9: val_loss improved from 0.50339 to 0.49878, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7836 - auc_8: 0.8619 - loss: 0.4457 - precision_8: 0.7146 - recall_8: 0.7040 - val_accuracy: 0.7784 - val_auc_8: 0.0000e+00 - val_loss: 0.4988 - val_precision_8: 1.0000 - val_recall_8: 0.7784 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7823 - auc_8: 0.8603 - loss: 0.4460 - precision_8: 0.7116 - recall_8: 0.6928\n",
      "Epoch 10: val_loss did not improve from 0.49878\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7825 - auc_8: 0.8644 - loss: 0.4411 - precision_8: 0.7145 - recall_8: 0.6996 - val_accuracy: 0.7717 - val_auc_8: 0.0000e+00 - val_loss: 0.5054 - val_precision_8: 1.0000 - val_recall_8: 0.7717 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7803 - auc_8: 0.8561 - loss: 0.4535 - precision_8: 0.7103 - recall_8: 0.6866\n",
      "Epoch 11: val_loss improved from 0.49878 to 0.49836, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7847 - auc_8: 0.8625 - loss: 0.4444 - precision_8: 0.7167 - recall_8: 0.7040 - val_accuracy: 0.7748 - val_auc_8: 0.0000e+00 - val_loss: 0.4984 - val_precision_8: 1.0000 - val_recall_8: 0.7748 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7913 - auc_8: 0.8643 - loss: 0.4424 - precision_8: 0.7269 - recall_8: 0.6996\n",
      "Epoch 12: val_loss improved from 0.49836 to 0.48743, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7924 - auc_8: 0.8676 - loss: 0.4376 - precision_8: 0.7295 - recall_8: 0.7092 - val_accuracy: 0.7862 - val_auc_8: 0.0000e+00 - val_loss: 0.4874 - val_precision_8: 1.0000 - val_recall_8: 0.7862 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7894 - auc_8: 0.8616 - loss: 0.4462 - precision_8: 0.7227 - recall_8: 0.6999\n",
      "Epoch 13: val_loss improved from 0.48743 to 0.48295, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7922 - auc_8: 0.8684 - loss: 0.4366 - precision_8: 0.7282 - recall_8: 0.7112 - val_accuracy: 0.7784 - val_auc_8: 0.0000e+00 - val_loss: 0.4830 - val_precision_8: 1.0000 - val_recall_8: 0.7784 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001B[1m 87/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7975 - auc_8: 0.8679 - loss: 0.4363 - precision_8: 0.7312 - recall_8: 0.7155\n",
      "Epoch 14: val_loss improved from 0.48295 to 0.48041, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7987 - auc_8: 0.8715 - loss: 0.4313 - precision_8: 0.7370 - recall_8: 0.7201 - val_accuracy: 0.7874 - val_auc_8: 0.0000e+00 - val_loss: 0.4804 - val_precision_8: 1.0000 - val_recall_8: 0.7874 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001B[1m 97/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7951 - auc_8: 0.8637 - loss: 0.4426 - precision_8: 0.7325 - recall_8: 0.7044\n",
      "Epoch 15: val_loss did not improve from 0.48041\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7951 - auc_8: 0.8700 - loss: 0.4340 - precision_8: 0.7330 - recall_8: 0.7133 - val_accuracy: 0.7784 - val_auc_8: 0.0000e+00 - val_loss: 0.4872 - val_precision_8: 1.0000 - val_recall_8: 0.7784 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7933 - auc_8: 0.8672 - loss: 0.4371 - precision_8: 0.7303 - recall_8: 0.7006\n",
      "Epoch 16: val_loss improved from 0.48041 to 0.47656, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7969 - auc_8: 0.8737 - loss: 0.4279 - precision_8: 0.7349 - recall_8: 0.7169 - val_accuracy: 0.7893 - val_auc_8: 0.0000e+00 - val_loss: 0.4766 - val_precision_8: 1.0000 - val_recall_8: 0.7893 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001B[1m 87/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7977 - auc_8: 0.8698 - loss: 0.4325 - precision_8: 0.7296 - recall_8: 0.7189\n",
      "Epoch 17: val_loss did not improve from 0.47656\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8001 - auc_8: 0.8742 - loss: 0.4272 - precision_8: 0.7351 - recall_8: 0.7298 - val_accuracy: 0.7929 - val_auc_8: 0.0000e+00 - val_loss: 0.4792 - val_precision_8: 1.0000 - val_recall_8: 0.7929 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7926 - auc_8: 0.8670 - loss: 0.4388 - precision_8: 0.7277 - recall_8: 0.7027\n",
      "Epoch 18: val_loss improved from 0.47656 to 0.47231, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7957 - auc_8: 0.8747 - loss: 0.4276 - precision_8: 0.7344 - recall_8: 0.7128 - val_accuracy: 0.7941 - val_auc_8: 0.0000e+00 - val_loss: 0.4723 - val_precision_8: 1.0000 - val_recall_8: 0.7941 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7974 - auc_8: 0.8741 - loss: 0.4266 - precision_8: 0.7255 - recall_8: 0.7280\n",
      "Epoch 19: val_loss improved from 0.47231 to 0.46996, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7982 - auc_8: 0.8775 - loss: 0.4220 - precision_8: 0.7313 - recall_8: 0.7302 - val_accuracy: 0.8013 - val_auc_8: 0.0000e+00 - val_loss: 0.4700 - val_precision_8: 1.0000 - val_recall_8: 0.8013 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7932 - auc_8: 0.8709 - loss: 0.4308 - precision_8: 0.7247 - recall_8: 0.7133\n",
      "Epoch 20: val_loss improved from 0.46996 to 0.46372, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7989 - auc_8: 0.8772 - loss: 0.4220 - precision_8: 0.7344 - recall_8: 0.7261 - val_accuracy: 0.7959 - val_auc_8: 0.0000e+00 - val_loss: 0.4637 - val_precision_8: 1.0000 - val_recall_8: 0.7959 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7978 - auc_8: 0.8737 - loss: 0.4281 - precision_8: 0.7310 - recall_8: 0.7183\n",
      "Epoch 21: val_loss did not improve from 0.46372\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8016 - auc_8: 0.8786 - loss: 0.4207 - precision_8: 0.7365 - recall_8: 0.7330 - val_accuracy: 0.7874 - val_auc_8: 0.0000e+00 - val_loss: 0.4765 - val_precision_8: 1.0000 - val_recall_8: 0.7874 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001B[1m 82/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7890 - auc_8: 0.8705 - loss: 0.4307 - precision_8: 0.7180 - recall_8: 0.7056\n",
      "Epoch 22: val_loss did not improve from 0.46372\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7969 - auc_8: 0.8780 - loss: 0.4211 - precision_8: 0.7309 - recall_8: 0.7253 - val_accuracy: 0.7953 - val_auc_8: 0.0000e+00 - val_loss: 0.4723 - val_precision_8: 1.0000 - val_recall_8: 0.7953 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8016 - auc_8: 0.8736 - loss: 0.4282 - precision_8: 0.7430 - recall_8: 0.7107\n",
      "Epoch 23: val_loss did not improve from 0.46372\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8026 - auc_8: 0.8791 - loss: 0.4197 - precision_8: 0.7422 - recall_8: 0.7257 - val_accuracy: 0.7965 - val_auc_8: 0.0000e+00 - val_loss: 0.4651 - val_precision_8: 1.0000 - val_recall_8: 0.7965 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8040 - auc_8: 0.8801 - loss: 0.4177 - precision_8: 0.7403 - recall_8: 0.7252\n",
      "Epoch 24: val_loss improved from 0.46372 to 0.46212, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8081 - auc_8: 0.8856 - loss: 0.4092 - precision_8: 0.7467 - recall_8: 0.7386 - val_accuracy: 0.8062 - val_auc_8: 0.0000e+00 - val_loss: 0.4621 - val_precision_8: 1.0000 - val_recall_8: 0.8062 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7998 - auc_8: 0.8751 - loss: 0.4256 - precision_8: 0.7310 - recall_8: 0.7267\n",
      "Epoch 25: val_loss improved from 0.46212 to 0.45325, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8017 - auc_8: 0.8813 - loss: 0.4154 - precision_8: 0.7349 - recall_8: 0.7370 - val_accuracy: 0.8122 - val_auc_8: 0.0000e+00 - val_loss: 0.4532 - val_precision_8: 1.0000 - val_recall_8: 0.8122 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001B[1m 84/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7996 - auc_8: 0.8744 - loss: 0.4250 - precision_8: 0.7300 - recall_8: 0.7258\n",
      "Epoch 26: val_loss improved from 0.45325 to 0.44805, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8058 - auc_8: 0.8815 - loss: 0.4147 - precision_8: 0.7418 - recall_8: 0.7394 - val_accuracy: 0.8116 - val_auc_8: 0.0000e+00 - val_loss: 0.4480 - val_precision_8: 1.0000 - val_recall_8: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8094 - auc_8: 0.8822 - loss: 0.4145 - precision_8: 0.7438 - recall_8: 0.7414\n",
      "Epoch 27: val_loss did not improve from 0.44805\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8079 - auc_8: 0.8859 - loss: 0.4094 - precision_8: 0.7456 - recall_8: 0.7402 - val_accuracy: 0.8098 - val_auc_8: 0.0000e+00 - val_loss: 0.4531 - val_precision_8: 1.0000 - val_recall_8: 0.8098 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8110 - auc_8: 0.8841 - loss: 0.4124 - precision_8: 0.7449 - recall_8: 0.7442\n",
      "Epoch 28: val_loss did not improve from 0.44805\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8132 - auc_8: 0.8879 - loss: 0.4054 - precision_8: 0.7504 - recall_8: 0.7519 - val_accuracy: 0.8001 - val_auc_8: 0.0000e+00 - val_loss: 0.4571 - val_precision_8: 1.0000 - val_recall_8: 0.8001 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001B[1m103/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8074 - auc_8: 0.8839 - loss: 0.4112 - precision_8: 0.7467 - recall_8: 0.7270\n",
      "Epoch 29: val_loss did not improve from 0.44805\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8124 - auc_8: 0.8884 - loss: 0.4047 - precision_8: 0.7515 - recall_8: 0.7467 - val_accuracy: 0.8128 - val_auc_8: 0.0000e+00 - val_loss: 0.4513 - val_precision_8: 1.0000 - val_recall_8: 0.8128 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8037 - auc_8: 0.8788 - loss: 0.4191 - precision_8: 0.7368 - recall_8: 0.7310\n",
      "Epoch 30: val_loss did not improve from 0.44805\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8123 - auc_8: 0.8892 - loss: 0.4036 - precision_8: 0.7498 - recall_8: 0.7495 - val_accuracy: 0.8013 - val_auc_8: 0.0000e+00 - val_loss: 0.4573 - val_precision_8: 1.0000 - val_recall_8: 0.8013 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8059 - auc_8: 0.8857 - loss: 0.4085 - precision_8: 0.7385 - recall_8: 0.7365\n",
      "Epoch 31: val_loss did not improve from 0.44805\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8108 - auc_8: 0.8898 - loss: 0.4022 - precision_8: 0.7468 - recall_8: 0.7495 - val_accuracy: 0.8080 - val_auc_8: 0.0000e+00 - val_loss: 0.4508 - val_precision_8: 1.0000 - val_recall_8: 0.8080 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8067 - auc_8: 0.8846 - loss: 0.4093 - precision_8: 0.7409 - recall_8: 0.7353\n",
      "Epoch 32: val_loss improved from 0.44805 to 0.44295, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8100 - auc_8: 0.8906 - loss: 0.3999 - precision_8: 0.7469 - recall_8: 0.7463 - val_accuracy: 0.8170 - val_auc_8: 0.0000e+00 - val_loss: 0.4429 - val_precision_8: 1.0000 - val_recall_8: 0.8170 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8042 - auc_8: 0.8833 - loss: 0.4113 - precision_8: 0.7374 - recall_8: 0.7309\n",
      "Epoch 33: val_loss did not improve from 0.44295\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8112 - auc_8: 0.8891 - loss: 0.4031 - precision_8: 0.7471 - recall_8: 0.7507 - val_accuracy: 0.8068 - val_auc_8: 0.0000e+00 - val_loss: 0.4535 - val_precision_8: 1.0000 - val_recall_8: 0.8068 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8099 - auc_8: 0.8828 - loss: 0.4121 - precision_8: 0.7499 - recall_8: 0.7309\n",
      "Epoch 34: val_loss improved from 0.44295 to 0.43162, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8102 - auc_8: 0.8884 - loss: 0.4031 - precision_8: 0.7478 - recall_8: 0.7451 - val_accuracy: 0.8170 - val_auc_8: 0.0000e+00 - val_loss: 0.4316 - val_precision_8: 1.0000 - val_recall_8: 0.8170 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8083 - auc_8: 0.8898 - loss: 0.4013 - precision_8: 0.7497 - recall_8: 0.7240\n",
      "Epoch 35: val_loss did not improve from 0.43162\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8146 - auc_8: 0.8936 - loss: 0.3957 - precision_8: 0.7560 - recall_8: 0.7463 - val_accuracy: 0.8116 - val_auc_8: 0.0000e+00 - val_loss: 0.4381 - val_precision_8: 1.0000 - val_recall_8: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001B[1m 82/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8060 - auc_8: 0.8855 - loss: 0.4079 - precision_8: 0.7414 - recall_8: 0.7282\n",
      "Epoch 36: val_loss did not improve from 0.43162\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8130 - auc_8: 0.8919 - loss: 0.3981 - precision_8: 0.7513 - recall_8: 0.7495 - val_accuracy: 0.8200 - val_auc_8: 0.0000e+00 - val_loss: 0.4343 - val_precision_8: 1.0000 - val_recall_8: 0.8200 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8125 - auc_8: 0.8922 - loss: 0.3973 - precision_8: 0.7541 - recall_8: 0.7315\n",
      "Epoch 37: val_loss did not improve from 0.43162\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8189 - auc_8: 0.8987 - loss: 0.3867 - precision_8: 0.7597 - recall_8: 0.7563 - val_accuracy: 0.8213 - val_auc_8: 0.0000e+00 - val_loss: 0.4357 - val_precision_8: 1.0000 - val_recall_8: 0.8213 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8152 - auc_8: 0.8938 - loss: 0.3941 - precision_8: 0.7559 - recall_8: 0.7396\n",
      "Epoch 38: val_loss did not improve from 0.43162\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8207 - auc_8: 0.8982 - loss: 0.3876 - precision_8: 0.7636 - recall_8: 0.7559 - val_accuracy: 0.8219 - val_auc_8: 0.0000e+00 - val_loss: 0.4373 - val_precision_8: 1.0000 - val_recall_8: 0.8219 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8174 - auc_8: 0.8918 - loss: 0.3983 - precision_8: 0.7556 - recall_8: 0.7496\n",
      "Epoch 39: val_loss improved from 0.43162 to 0.41469, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8179 - auc_8: 0.8953 - loss: 0.3926 - precision_8: 0.7557 - recall_8: 0.7600 - val_accuracy: 0.8237 - val_auc_8: 0.0000e+00 - val_loss: 0.4147 - val_precision_8: 1.0000 - val_recall_8: 0.8237 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8201 - auc_8: 0.8981 - loss: 0.3871 - precision_8: 0.7588 - recall_8: 0.7530\n",
      "Epoch 40: val_loss improved from 0.41469 to 0.40611, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8236 - auc_8: 0.9010 - loss: 0.3829 - precision_8: 0.7661 - recall_8: 0.7624 - val_accuracy: 0.8321 - val_auc_8: 0.0000e+00 - val_loss: 0.4061 - val_precision_8: 1.0000 - val_recall_8: 0.8321 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001B[1m 91/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8142 - auc_8: 0.8921 - loss: 0.3974 - precision_8: 0.7497 - recall_8: 0.7469\n",
      "Epoch 41: val_loss did not improve from 0.40611\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8220 - auc_8: 0.8978 - loss: 0.3882 - precision_8: 0.7614 - recall_8: 0.7648 - val_accuracy: 0.8176 - val_auc_8: 0.0000e+00 - val_loss: 0.4276 - val_precision_8: 1.0000 - val_recall_8: 0.8176 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8220 - auc_8: 0.8981 - loss: 0.3873 - precision_8: 0.7642 - recall_8: 0.7507\n",
      "Epoch 42: val_loss did not improve from 0.40611\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8241 - auc_8: 0.9010 - loss: 0.3828 - precision_8: 0.7679 - recall_8: 0.7608 - val_accuracy: 0.8261 - val_auc_8: 0.0000e+00 - val_loss: 0.4163 - val_precision_8: 1.0000 - val_recall_8: 0.8261 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8186 - auc_8: 0.8976 - loss: 0.3886 - precision_8: 0.7522 - recall_8: 0.7613\n",
      "Epoch 43: val_loss did not improve from 0.40611\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8230 - auc_8: 0.9008 - loss: 0.3837 - precision_8: 0.7623 - recall_8: 0.7672 - val_accuracy: 0.8207 - val_auc_8: 0.0000e+00 - val_loss: 0.4245 - val_precision_8: 1.0000 - val_recall_8: 0.8207 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001B[1m 88/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8226 - auc_8: 0.8918 - loss: 0.3994 - precision_8: 0.7623 - recall_8: 0.7562\n",
      "Epoch 44: val_loss improved from 0.40611 to 0.40093, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8269 - auc_8: 0.9017 - loss: 0.3834 - precision_8: 0.7714 - recall_8: 0.7652 - val_accuracy: 0.8364 - val_auc_8: 0.0000e+00 - val_loss: 0.4009 - val_precision_8: 1.0000 - val_recall_8: 0.8364 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001B[1m 92/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8214 - auc_8: 0.8990 - loss: 0.3858 - precision_8: 0.7610 - recall_8: 0.7540\n",
      "Epoch 45: val_loss did not improve from 0.40093\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8283 - auc_8: 0.9051 - loss: 0.3754 - precision_8: 0.7701 - recall_8: 0.7729 - val_accuracy: 0.8309 - val_auc_8: 0.0000e+00 - val_loss: 0.4070 - val_precision_8: 1.0000 - val_recall_8: 0.8309 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8218 - auc_8: 0.9010 - loss: 0.3822 - precision_8: 0.7607 - recall_8: 0.7576\n",
      "Epoch 46: val_loss did not improve from 0.40093\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8288 - auc_8: 0.9062 - loss: 0.3729 - precision_8: 0.7682 - recall_8: 0.7781 - val_accuracy: 0.8321 - val_auc_8: 0.0000e+00 - val_loss: 0.4129 - val_precision_8: 1.0000 - val_recall_8: 0.8321 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001B[1m 86/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8240 - auc_8: 0.8995 - loss: 0.3843 - precision_8: 0.7654 - recall_8: 0.7546\n",
      "Epoch 47: val_loss did not improve from 0.40093\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8307 - auc_8: 0.9073 - loss: 0.3716 - precision_8: 0.7742 - recall_8: 0.7745 - val_accuracy: 0.8315 - val_auc_8: 0.0000e+00 - val_loss: 0.4165 - val_precision_8: 1.0000 - val_recall_8: 0.8315 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001B[1m 88/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8271 - auc_8: 0.9048 - loss: 0.3752 - precision_8: 0.7713 - recall_8: 0.7564\n",
      "Epoch 48: val_loss improved from 0.40093 to 0.39195, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8295 - auc_8: 0.9080 - loss: 0.3703 - precision_8: 0.7723 - recall_8: 0.7733 - val_accuracy: 0.8364 - val_auc_8: 0.0000e+00 - val_loss: 0.3919 - val_precision_8: 1.0000 - val_recall_8: 0.8364 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001B[1m 87/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8267 - auc_8: 0.9075 - loss: 0.3710 - precision_8: 0.7694 - recall_8: 0.7586\n",
      "Epoch 49: val_loss did not improve from 0.39195\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8322 - auc_8: 0.9076 - loss: 0.3708 - precision_8: 0.7740 - recall_8: 0.7805 - val_accuracy: 0.8394 - val_auc_8: 0.0000e+00 - val_loss: 0.3953 - val_precision_8: 1.0000 - val_recall_8: 0.8394 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001B[1m 90/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8322 - auc_8: 0.9056 - loss: 0.3740 - precision_8: 0.7768 - recall_8: 0.7667\n",
      "Epoch 50: val_loss did not improve from 0.39195\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8265 - auc_8: 0.9086 - loss: 0.3681 - precision_8: 0.7670 - recall_8: 0.7716 - val_accuracy: 0.8400 - val_auc_8: 0.0000e+00 - val_loss: 0.3956 - val_precision_8: 1.0000 - val_recall_8: 0.8400 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001B[1m102/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8354 - auc_8: 0.9060 - loss: 0.3734 - precision_8: 0.7765 - recall_8: 0.7807\n",
      "Epoch 51: val_loss did not improve from 0.39195\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8369 - auc_8: 0.9083 - loss: 0.3697 - precision_8: 0.7791 - recall_8: 0.7886 - val_accuracy: 0.8376 - val_auc_8: 0.0000e+00 - val_loss: 0.3966 - val_precision_8: 1.0000 - val_recall_8: 0.8376 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001B[1m 90/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8223 - auc_8: 0.8996 - loss: 0.3849 - precision_8: 0.7633 - recall_8: 0.7526\n",
      "Epoch 52: val_loss improved from 0.39195 to 0.38700, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8295 - auc_8: 0.9073 - loss: 0.3712 - precision_8: 0.7706 - recall_8: 0.7765 - val_accuracy: 0.8442 - val_auc_8: 0.0000e+00 - val_loss: 0.3870 - val_precision_8: 1.0000 - val_recall_8: 0.8442 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001B[1m 88/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8254 - auc_8: 0.9058 - loss: 0.3723 - precision_8: 0.7622 - recall_8: 0.7668\n",
      "Epoch 53: val_loss did not improve from 0.38700\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8324 - auc_8: 0.9099 - loss: 0.3660 - precision_8: 0.7738 - recall_8: 0.7813 - val_accuracy: 0.8400 - val_auc_8: 0.0000e+00 - val_loss: 0.3997 - val_precision_8: 1.0000 - val_recall_8: 0.8400 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001B[1m 87/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8303 - auc_8: 0.9060 - loss: 0.3714 - precision_8: 0.7668 - recall_8: 0.7772\n",
      "Epoch 54: val_loss did not improve from 0.38700\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8374 - auc_8: 0.9135 - loss: 0.3590 - precision_8: 0.7808 - recall_8: 0.7874 - val_accuracy: 0.8333 - val_auc_8: 0.0000e+00 - val_loss: 0.4121 - val_precision_8: 1.0000 - val_recall_8: 0.8333 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001B[1m 91/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8362 - auc_8: 0.9120 - loss: 0.3613 - precision_8: 0.7794 - recall_8: 0.7772\n",
      "Epoch 55: val_loss did not improve from 0.38700\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8362 - auc_8: 0.9152 - loss: 0.3550 - precision_8: 0.7787 - recall_8: 0.7865 - val_accuracy: 0.8454 - val_auc_8: 0.0000e+00 - val_loss: 0.3922 - val_precision_8: 1.0000 - val_recall_8: 0.8454 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8276 - auc_8: 0.9100 - loss: 0.3642 - precision_8: 0.7688 - recall_8: 0.7646\n",
      "Epoch 56: val_loss improved from 0.38700 to 0.36473, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8351 - auc_8: 0.9148 - loss: 0.3561 - precision_8: 0.7779 - recall_8: 0.7841 - val_accuracy: 0.8593 - val_auc_8: 0.0000e+00 - val_loss: 0.3647 - val_precision_8: 1.0000 - val_recall_8: 0.8593 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8294 - auc_8: 0.9059 - loss: 0.3724 - precision_8: 0.7700 - recall_8: 0.7689\n",
      "Epoch 57: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8339 - auc_8: 0.9136 - loss: 0.3576 - precision_8: 0.7756 - recall_8: 0.7837 - val_accuracy: 0.8333 - val_auc_8: 0.0000e+00 - val_loss: 0.3987 - val_precision_8: 1.0000 - val_recall_8: 0.8333 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8311 - auc_8: 0.9113 - loss: 0.3626 - precision_8: 0.7704 - recall_8: 0.7752\n",
      "Epoch 58: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8386 - auc_8: 0.9153 - loss: 0.3548 - precision_8: 0.7808 - recall_8: 0.7918 - val_accuracy: 0.8502 - val_auc_8: 0.0000e+00 - val_loss: 0.3870 - val_precision_8: 1.0000 - val_recall_8: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8352 - auc_8: 0.9109 - loss: 0.3652 - precision_8: 0.7768 - recall_8: 0.7789\n",
      "Epoch 59: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8378 - auc_8: 0.9139 - loss: 0.3595 - precision_8: 0.7803 - recall_8: 0.7898 - val_accuracy: 0.8539 - val_auc_8: 0.0000e+00 - val_loss: 0.3886 - val_precision_8: 1.0000 - val_recall_8: 0.8539 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001B[1m 93/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8362 - auc_8: 0.9119 - loss: 0.3616 - precision_8: 0.7777 - recall_8: 0.7803\n",
      "Epoch 60: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8422 - auc_8: 0.9169 - loss: 0.3528 - precision_8: 0.7853 - recall_8: 0.7970 - val_accuracy: 0.8484 - val_auc_8: 0.0000e+00 - val_loss: 0.3809 - val_precision_8: 1.0000 - val_recall_8: 0.8484 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001B[1m 91/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8357 - auc_8: 0.9089 - loss: 0.3665 - precision_8: 0.7744 - recall_8: 0.7845\n",
      "Epoch 61: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8386 - auc_8: 0.9151 - loss: 0.3548 - precision_8: 0.7810 - recall_8: 0.7914 - val_accuracy: 0.8466 - val_auc_8: 0.0000e+00 - val_loss: 0.3820 - val_precision_8: 1.0000 - val_recall_8: 0.8466 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001B[1m 95/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8387 - auc_8: 0.9152 - loss: 0.3543 - precision_8: 0.7784 - recall_8: 0.7897\n",
      "Epoch 62: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8422 - auc_8: 0.9180 - loss: 0.3493 - precision_8: 0.7860 - recall_8: 0.7958 - val_accuracy: 0.8617 - val_auc_8: 0.0000e+00 - val_loss: 0.3725 - val_precision_8: 1.0000 - val_recall_8: 0.8617 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8400 - auc_8: 0.9159 - loss: 0.3528 - precision_8: 0.7845 - recall_8: 0.7828\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.36473\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8420 - auc_8: 0.9181 - loss: 0.3502 - precision_8: 0.7873 - recall_8: 0.7930 - val_accuracy: 0.8587 - val_auc_8: 0.0000e+00 - val_loss: 0.3749 - val_precision_8: 1.0000 - val_recall_8: 0.8587 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8497 - auc_8: 0.9182 - loss: 0.3496 - precision_8: 0.8000 - recall_8: 0.7927\n",
      "Epoch 64: val_loss improved from 0.36473 to 0.35626, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8499 - auc_8: 0.9233 - loss: 0.3399 - precision_8: 0.8038 - recall_8: 0.7934 - val_accuracy: 0.8647 - val_auc_8: 0.0000e+00 - val_loss: 0.3563 - val_precision_8: 1.0000 - val_recall_8: 0.8647 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8405 - auc_8: 0.9179 - loss: 0.3489 - precision_8: 0.7823 - recall_8: 0.7894\n",
      "Epoch 65: val_loss did not improve from 0.35626\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8445 - auc_8: 0.9213 - loss: 0.3420 - precision_8: 0.7900 - recall_8: 0.7970 - val_accuracy: 0.8611 - val_auc_8: 0.0000e+00 - val_loss: 0.3643 - val_precision_8: 1.0000 - val_recall_8: 0.8611 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8477 - auc_8: 0.9223 - loss: 0.3396 - precision_8: 0.7904 - recall_8: 0.8013\n",
      "Epoch 66: val_loss did not improve from 0.35626\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8470 - auc_8: 0.9247 - loss: 0.3357 - precision_8: 0.7919 - recall_8: 0.8031 - val_accuracy: 0.8708 - val_auc_8: 0.0000e+00 - val_loss: 0.3569 - val_precision_8: 1.0000 - val_recall_8: 0.8708 - learning_rate: 5.0000e-04\n",
      "Epoch 67/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8382 - auc_8: 0.9194 - loss: 0.3442 - precision_8: 0.7743 - recall_8: 0.7952\n",
      "Epoch 67: val_loss improved from 0.35626 to 0.35172, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8475 - auc_8: 0.9261 - loss: 0.3324 - precision_8: 0.7921 - recall_8: 0.8043 - val_accuracy: 0.8726 - val_auc_8: 0.0000e+00 - val_loss: 0.3517 - val_precision_8: 1.0000 - val_recall_8: 0.8726 - learning_rate: 5.0000e-04\n",
      "Epoch 68/150\n",
      "\u001B[1m 94/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8513 - auc_8: 0.9227 - loss: 0.3415 - precision_8: 0.7966 - recall_8: 0.8041\n",
      "Epoch 68: val_loss did not improve from 0.35172\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8514 - auc_8: 0.9242 - loss: 0.3375 - precision_8: 0.7997 - recall_8: 0.8055 - val_accuracy: 0.8653 - val_auc_8: 0.0000e+00 - val_loss: 0.3577 - val_precision_8: 1.0000 - val_recall_8: 0.8653 - learning_rate: 5.0000e-04\n",
      "Epoch 69/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8588 - auc_8: 0.9308 - loss: 0.3222 - precision_8: 0.8007 - recall_8: 0.8253\n",
      "Epoch 69: val_loss improved from 0.35172 to 0.34520, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8609 - auc_8: 0.9342 - loss: 0.3156 - precision_8: 0.8107 - recall_8: 0.8208 - val_accuracy: 0.8804 - val_auc_8: 0.0000e+00 - val_loss: 0.3452 - val_precision_8: 1.0000 - val_recall_8: 0.8804 - learning_rate: 5.0000e-04\n",
      "Epoch 70/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8484 - auc_8: 0.9268 - loss: 0.3305 - precision_8: 0.7924 - recall_8: 0.8011\n",
      "Epoch 70: val_loss improved from 0.34520 to 0.34317, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8513 - auc_8: 0.9285 - loss: 0.3281 - precision_8: 0.7994 - recall_8: 0.8055 - val_accuracy: 0.8756 - val_auc_8: 0.0000e+00 - val_loss: 0.3432 - val_precision_8: 1.0000 - val_recall_8: 0.8756 - learning_rate: 5.0000e-04\n",
      "Epoch 71/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8529 - auc_8: 0.9253 - loss: 0.3336 - precision_8: 0.7980 - recall_8: 0.8069\n",
      "Epoch 71: val_loss did not improve from 0.34317\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8568 - auc_8: 0.9298 - loss: 0.3246 - precision_8: 0.8054 - recall_8: 0.8151 - val_accuracy: 0.8768 - val_auc_8: 0.0000e+00 - val_loss: 0.3453 - val_precision_8: 1.0000 - val_recall_8: 0.8768 - learning_rate: 5.0000e-04\n",
      "Epoch 72/150\n",
      "\u001B[1m 91/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8444 - auc_8: 0.9233 - loss: 0.3377 - precision_8: 0.7818 - recall_8: 0.8049\n",
      "Epoch 72: val_loss did not improve from 0.34317\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8496 - auc_8: 0.9271 - loss: 0.3304 - precision_8: 0.7968 - recall_8: 0.8039 - val_accuracy: 0.8810 - val_auc_8: 0.0000e+00 - val_loss: 0.3438 - val_precision_8: 1.0000 - val_recall_8: 0.8810 - learning_rate: 5.0000e-04\n",
      "Epoch 73/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8535 - auc_8: 0.9277 - loss: 0.3282 - precision_8: 0.7941 - recall_8: 0.8167\n",
      "Epoch 73: val_loss improved from 0.34317 to 0.33811, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8564 - auc_8: 0.9304 - loss: 0.3235 - precision_8: 0.8032 - recall_8: 0.8172 - val_accuracy: 0.8708 - val_auc_8: 0.0000e+00 - val_loss: 0.3381 - val_precision_8: 1.0000 - val_recall_8: 0.8708 - learning_rate: 5.0000e-04\n",
      "Epoch 74/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8450 - auc_8: 0.9258 - loss: 0.3312 - precision_8: 0.7845 - recall_8: 0.8018\n",
      "Epoch 74: val_loss did not improve from 0.33811\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8547 - auc_8: 0.9304 - loss: 0.3228 - precision_8: 0.7998 - recall_8: 0.8172 - val_accuracy: 0.8659 - val_auc_8: 0.0000e+00 - val_loss: 0.3484 - val_precision_8: 1.0000 - val_recall_8: 0.8659 - learning_rate: 5.0000e-04\n",
      "Epoch 75/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8497 - auc_8: 0.9246 - loss: 0.3350 - precision_8: 0.7875 - recall_8: 0.8142\n",
      "Epoch 75: val_loss did not improve from 0.33811\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8519 - auc_8: 0.9304 - loss: 0.3226 - precision_8: 0.7978 - recall_8: 0.8103 - val_accuracy: 0.8696 - val_auc_8: 0.0000e+00 - val_loss: 0.3435 - val_precision_8: 1.0000 - val_recall_8: 0.8696 - learning_rate: 5.0000e-04\n",
      "Epoch 76/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8424 - auc_8: 0.9251 - loss: 0.3332 - precision_8: 0.7844 - recall_8: 0.7930\n",
      "Epoch 76: val_loss did not improve from 0.33811\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8500 - auc_8: 0.9294 - loss: 0.3247 - precision_8: 0.7973 - recall_8: 0.8047 - val_accuracy: 0.8768 - val_auc_8: 0.0000e+00 - val_loss: 0.3419 - val_precision_8: 1.0000 - val_recall_8: 0.8768 - learning_rate: 5.0000e-04\n",
      "Epoch 77/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8594 - auc_8: 0.9304 - loss: 0.3219 - precision_8: 0.8097 - recall_8: 0.8113\n",
      "Epoch 77: val_loss improved from 0.33811 to 0.33370, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8603 - auc_8: 0.9329 - loss: 0.3179 - precision_8: 0.8123 - recall_8: 0.8159 - val_accuracy: 0.8841 - val_auc_8: 0.0000e+00 - val_loss: 0.3337 - val_precision_8: 1.0000 - val_recall_8: 0.8841 - learning_rate: 5.0000e-04\n",
      "Epoch 78/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8518 - auc_8: 0.9256 - loss: 0.3333 - precision_8: 0.7964 - recall_8: 0.8065\n",
      "Epoch 78: val_loss did not improve from 0.33370\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8517 - auc_8: 0.9290 - loss: 0.3258 - precision_8: 0.8013 - recall_8: 0.8039 - val_accuracy: 0.8702 - val_auc_8: 0.0000e+00 - val_loss: 0.3535 - val_precision_8: 1.0000 - val_recall_8: 0.8702 - learning_rate: 5.0000e-04\n",
      "Epoch 79/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8446 - auc_8: 0.9256 - loss: 0.3325 - precision_8: 0.7867 - recall_8: 0.7971\n",
      "Epoch 79: val_loss did not improve from 0.33370\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8502 - auc_8: 0.9286 - loss: 0.3270 - precision_8: 0.7969 - recall_8: 0.8059 - val_accuracy: 0.8841 - val_auc_8: 0.0000e+00 - val_loss: 0.3352 - val_precision_8: 1.0000 - val_recall_8: 0.8841 - learning_rate: 5.0000e-04\n",
      "Epoch 80/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8529 - auc_8: 0.9316 - loss: 0.3199 - precision_8: 0.7960 - recall_8: 0.8101\n",
      "Epoch 80: val_loss improved from 0.33370 to 0.33026, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8608 - auc_8: 0.9348 - loss: 0.3137 - precision_8: 0.8103 - recall_8: 0.8208 - val_accuracy: 0.8841 - val_auc_8: 0.0000e+00 - val_loss: 0.3303 - val_precision_8: 1.0000 - val_recall_8: 0.8841 - learning_rate: 5.0000e-04\n",
      "Epoch 81/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8605 - auc_8: 0.9325 - loss: 0.3170 - precision_8: 0.8077 - recall_8: 0.8185\n",
      "Epoch 81: val_loss improved from 0.33026 to 0.32202, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8621 - auc_8: 0.9344 - loss: 0.3141 - precision_8: 0.8148 - recall_8: 0.8184 - val_accuracy: 0.8907 - val_auc_8: 0.0000e+00 - val_loss: 0.3220 - val_precision_8: 1.0000 - val_recall_8: 0.8907 - learning_rate: 5.0000e-04\n",
      "Epoch 82/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8528 - auc_8: 0.9283 - loss: 0.3257 - precision_8: 0.7934 - recall_8: 0.8159\n",
      "Epoch 82: val_loss did not improve from 0.32202\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8603 - auc_8: 0.9330 - loss: 0.3165 - precision_8: 0.8072 - recall_8: 0.8244 - val_accuracy: 0.8804 - val_auc_8: 0.0000e+00 - val_loss: 0.3306 - val_precision_8: 1.0000 - val_recall_8: 0.8804 - learning_rate: 5.0000e-04\n",
      "Epoch 83/150\n",
      "\u001B[1m 89/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8569 - auc_8: 0.9293 - loss: 0.3236 - precision_8: 0.8035 - recall_8: 0.8118\n",
      "Epoch 83: val_loss improved from 0.32202 to 0.31806, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8596 - auc_8: 0.9342 - loss: 0.3142 - precision_8: 0.8107 - recall_8: 0.8159 - val_accuracy: 0.8925 - val_auc_8: 0.0000e+00 - val_loss: 0.3181 - val_precision_8: 1.0000 - val_recall_8: 0.8925 - learning_rate: 5.0000e-04\n",
      "Epoch 84/150\n",
      "\u001B[1m 97/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8547 - auc_8: 0.9304 - loss: 0.3233 - precision_8: 0.7920 - recall_8: 0.8243\n",
      "Epoch 84: val_loss did not improve from 0.31806\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8540 - auc_8: 0.9318 - loss: 0.3207 - precision_8: 0.7968 - recall_8: 0.8196 - val_accuracy: 0.8762 - val_auc_8: 0.0000e+00 - val_loss: 0.3294 - val_precision_8: 1.0000 - val_recall_8: 0.8762 - learning_rate: 5.0000e-04\n",
      "Epoch 85/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8506 - auc_8: 0.9308 - loss: 0.3203 - precision_8: 0.7889 - recall_8: 0.8153\n",
      "Epoch 85: val_loss improved from 0.31806 to 0.31215, saving model to models/neural_network_best.keras\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8587 - auc_8: 0.9328 - loss: 0.3174 - precision_8: 0.8035 - recall_8: 0.8248 - val_accuracy: 0.8883 - val_auc_8: 0.0000e+00 - val_loss: 0.3122 - val_precision_8: 1.0000 - val_recall_8: 0.8883 - learning_rate: 5.0000e-04\n",
      "Epoch 86/150\n",
      "\u001B[1m102/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8572 - auc_8: 0.9299 - loss: 0.3224 - precision_8: 0.8041 - recall_8: 0.8126\n",
      "Epoch 86: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8624 - auc_8: 0.9340 - loss: 0.3142 - precision_8: 0.8129 - recall_8: 0.8224 - val_accuracy: 0.8841 - val_auc_8: 0.0000e+00 - val_loss: 0.3239 - val_precision_8: 1.0000 - val_recall_8: 0.8841 - learning_rate: 5.0000e-04\n",
      "Epoch 87/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8572 - auc_8: 0.9332 - loss: 0.3170 - precision_8: 0.8033 - recall_8: 0.8143\n",
      "Epoch 87: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8579 - auc_8: 0.9344 - loss: 0.3145 - precision_8: 0.8079 - recall_8: 0.8147 - val_accuracy: 0.8859 - val_auc_8: 0.0000e+00 - val_loss: 0.3281 - val_precision_8: 1.0000 - val_recall_8: 0.8859 - learning_rate: 5.0000e-04\n",
      "Epoch 88/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8586 - auc_8: 0.9316 - loss: 0.3202 - precision_8: 0.8053 - recall_8: 0.8156\n",
      "Epoch 88: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8615 - auc_8: 0.9344 - loss: 0.3146 - precision_8: 0.8150 - recall_8: 0.8159 - val_accuracy: 0.8853 - val_auc_8: 0.0000e+00 - val_loss: 0.3258 - val_precision_8: 1.0000 - val_recall_8: 0.8853 - learning_rate: 5.0000e-04\n",
      "Epoch 89/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8585 - auc_8: 0.9332 - loss: 0.3156 - precision_8: 0.8025 - recall_8: 0.8202\n",
      "Epoch 89: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8620 - auc_8: 0.9364 - loss: 0.3096 - precision_8: 0.8112 - recall_8: 0.8236 - val_accuracy: 0.8798 - val_auc_8: 0.0000e+00 - val_loss: 0.3267 - val_precision_8: 1.0000 - val_recall_8: 0.8798 - learning_rate: 5.0000e-04\n",
      "Epoch 90/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8618 - auc_8: 0.9356 - loss: 0.3108 - precision_8: 0.8111 - recall_8: 0.8173\n",
      "Epoch 90: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8639 - auc_8: 0.9374 - loss: 0.3072 - precision_8: 0.8149 - recall_8: 0.8244 - val_accuracy: 0.8907 - val_auc_8: 0.0000e+00 - val_loss: 0.3260 - val_precision_8: 1.0000 - val_recall_8: 0.8907 - learning_rate: 5.0000e-04\n",
      "Epoch 91/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8558 - auc_8: 0.9290 - loss: 0.3265 - precision_8: 0.7986 - recall_8: 0.8173\n",
      "Epoch 91: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8615 - auc_8: 0.9369 - loss: 0.3097 - precision_8: 0.8102 - recall_8: 0.8236 - val_accuracy: 0.8889 - val_auc_8: 0.0000e+00 - val_loss: 0.3209 - val_precision_8: 1.0000 - val_recall_8: 0.8889 - learning_rate: 5.0000e-04\n",
      "Epoch 92/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8551 - auc_8: 0.9302 - loss: 0.3233 - precision_8: 0.8020 - recall_8: 0.8093\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8585 - auc_8: 0.9343 - loss: 0.3144 - precision_8: 0.8085 - recall_8: 0.8159 - val_accuracy: 0.8822 - val_auc_8: 0.0000e+00 - val_loss: 0.3367 - val_precision_8: 1.0000 - val_recall_8: 0.8822 - learning_rate: 5.0000e-04\n",
      "Epoch 93/150\n",
      "\u001B[1m 97/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8645 - auc_8: 0.9359 - loss: 0.3102 - precision_8: 0.8094 - recall_8: 0.8303\n",
      "Epoch 93: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8656 - auc_8: 0.9390 - loss: 0.3037 - precision_8: 0.8177 - recall_8: 0.8256 - val_accuracy: 0.8865 - val_auc_8: 0.0000e+00 - val_loss: 0.3231 - val_precision_8: 1.0000 - val_recall_8: 0.8865 - learning_rate: 2.5000e-04\n",
      "Epoch 94/150\n",
      "\u001B[1m 84/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8600 - auc_8: 0.9355 - loss: 0.3107 - precision_8: 0.8023 - recall_8: 0.8237\n",
      "Epoch 94: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8650 - auc_8: 0.9372 - loss: 0.3081 - precision_8: 0.8147 - recall_8: 0.8284 - val_accuracy: 0.8859 - val_auc_8: 0.0000e+00 - val_loss: 0.3206 - val_precision_8: 1.0000 - val_recall_8: 0.8859 - learning_rate: 2.5000e-04\n",
      "Epoch 95/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8661 - auc_8: 0.9353 - loss: 0.3135 - precision_8: 0.8131 - recall_8: 0.8296\n",
      "Epoch 95: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8712 - auc_8: 0.9404 - loss: 0.3012 - precision_8: 0.8247 - recall_8: 0.8337 - val_accuracy: 0.8877 - val_auc_8: 0.0000e+00 - val_loss: 0.3168 - val_precision_8: 1.0000 - val_recall_8: 0.8877 - learning_rate: 2.5000e-04\n",
      "Epoch 96/150\n",
      "\u001B[1m102/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8632 - auc_8: 0.9377 - loss: 0.3051 - precision_8: 0.8056 - recall_8: 0.8316\n",
      "Epoch 96: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8668 - auc_8: 0.9389 - loss: 0.3029 - precision_8: 0.8148 - recall_8: 0.8345 - val_accuracy: 0.8841 - val_auc_8: 0.0000e+00 - val_loss: 0.3225 - val_precision_8: 1.0000 - val_recall_8: 0.8841 - learning_rate: 2.5000e-04\n",
      "Epoch 97/150\n",
      "\u001B[1m 99/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8518 - auc_8: 0.9336 - loss: 0.3147 - precision_8: 0.7935 - recall_8: 0.8106\n",
      "Epoch 97: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8620 - auc_8: 0.9385 - loss: 0.3048 - precision_8: 0.8117 - recall_8: 0.8228 - val_accuracy: 0.8877 - val_auc_8: 0.0000e+00 - val_loss: 0.3224 - val_precision_8: 1.0000 - val_recall_8: 0.8877 - learning_rate: 2.5000e-04\n",
      "Epoch 98/150\n",
      "\u001B[1m 97/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8628 - auc_8: 0.9401 - loss: 0.3008 - precision_8: 0.7988 - recall_8: 0.8425\n",
      "Epoch 98: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8638 - auc_8: 0.9411 - loss: 0.2987 - precision_8: 0.8101 - recall_8: 0.8317 - val_accuracy: 0.8913 - val_auc_8: 0.0000e+00 - val_loss: 0.3189 - val_precision_8: 1.0000 - val_recall_8: 0.8913 - learning_rate: 2.5000e-04\n",
      "Epoch 99/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8641 - auc_8: 0.9397 - loss: 0.2994 - precision_8: 0.8095 - recall_8: 0.8274\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8680 - auc_8: 0.9407 - loss: 0.2983 - precision_8: 0.8154 - recall_8: 0.8377 - val_accuracy: 0.8865 - val_auc_8: 0.0000e+00 - val_loss: 0.3195 - val_precision_8: 1.0000 - val_recall_8: 0.8865 - learning_rate: 2.5000e-04\n",
      "Epoch 100/150\n",
      "\u001B[1m101/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8606 - auc_8: 0.9382 - loss: 0.3063 - precision_8: 0.8084 - recall_8: 0.8172\n",
      "Epoch 100: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8683 - auc_8: 0.9413 - loss: 0.2984 - precision_8: 0.8218 - recall_8: 0.8284 - val_accuracy: 0.8865 - val_auc_8: 0.0000e+00 - val_loss: 0.3183 - val_precision_8: 1.0000 - val_recall_8: 0.8865 - learning_rate: 1.2500e-04\n",
      "Epoch 101/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8701 - auc_8: 0.9417 - loss: 0.2971 - precision_8: 0.8116 - recall_8: 0.8458\n",
      "Epoch 101: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8685 - auc_8: 0.9416 - loss: 0.2973 - precision_8: 0.8198 - recall_8: 0.8321 - val_accuracy: 0.8853 - val_auc_8: 0.0000e+00 - val_loss: 0.3168 - val_precision_8: 1.0000 - val_recall_8: 0.8853 - learning_rate: 1.2500e-04\n",
      "Epoch 102/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8616 - auc_8: 0.9362 - loss: 0.3097 - precision_8: 0.8042 - recall_8: 0.8282\n",
      "Epoch 102: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8647 - auc_8: 0.9381 - loss: 0.3061 - precision_8: 0.8140 - recall_8: 0.8284 - val_accuracy: 0.8835 - val_auc_8: 0.0000e+00 - val_loss: 0.3219 - val_precision_8: 1.0000 - val_recall_8: 0.8835 - learning_rate: 1.2500e-04\n",
      "Epoch 103/150\n",
      "\u001B[1m100/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8666 - auc_8: 0.9393 - loss: 0.3022 - precision_8: 0.8080 - recall_8: 0.8396\n",
      "Epoch 103: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8683 - auc_8: 0.9415 - loss: 0.2967 - precision_8: 0.8183 - recall_8: 0.8341 - val_accuracy: 0.8877 - val_auc_8: 0.0000e+00 - val_loss: 0.3200 - val_precision_8: 1.0000 - val_recall_8: 0.8877 - learning_rate: 1.2500e-04\n",
      "Epoch 104/150\n",
      "\u001B[1m 98/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8597 - auc_8: 0.9374 - loss: 0.3083 - precision_8: 0.8084 - recall_8: 0.8141\n",
      "Epoch 104: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8612 - auc_8: 0.9396 - loss: 0.3025 - precision_8: 0.8138 - recall_8: 0.8168 - val_accuracy: 0.8865 - val_auc_8: 0.0000e+00 - val_loss: 0.3189 - val_precision_8: 1.0000 - val_recall_8: 0.8865 - learning_rate: 1.2500e-04\n",
      "Epoch 105/150\n",
      "\u001B[1m 96/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8641 - auc_8: 0.9435 - loss: 0.2910 - precision_8: 0.8100 - recall_8: 0.8273\n",
      "Epoch 105: val_loss did not improve from 0.31215\n",
      "\u001B[1m104/104\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8676 - auc_8: 0.9453 - loss: 0.2872 - precision_8: 0.8199 - recall_8: 0.8288 - val_accuracy: 0.8871 - val_auc_8: 0.0000e+00 - val_loss: 0.3153 - val_precision_8: 1.0000 - val_recall_8: 0.8871 - learning_rate: 1.2500e-04\n",
      "Epoch 105: early stopping\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "\n",
      "Optimized model training completed\n",
      "Total epochs: 105\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:32:24.969676Z",
     "start_time": "2025-12-12T01:32:24.681261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#evaluate optimized model\n",
    "print(\"Step 6: Optimized model evaluation\")\n",
    "y_pred_prob_opt= nn_optimized.predict(X_test, verbose=0).flatten()\n",
    "y_pred_opt = (y_pred_prob_opt>0.5).astype(int)\n",
    "\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_opt)\n",
    "optimized_precision = precision_score(y_test, y_pred_opt)\n",
    "optimized_recall = recall_score(y_test, y_pred_opt)\n",
    "optimized_f1 = f1_score(y_test, y_pred_opt)\n",
    "optimized_roc_auc = roc_auc_score(y_test, y_pred_prob_opt)\n",
    "\n",
    "print(\"Optimized model performance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Accuracy:  {optimized_accuracy:.4f}\")\n",
    "print(f\"Precision: {optimized_precision:.4f}\")\n",
    "print(f\"Recall:    {optimized_recall:.4f}\")\n",
    "print(f\"F1-Score:  {optimized_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {optimized_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_opt, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_opt)\n",
    "print(f\"\\nTrue Negatives: {cm_opt[0,0]}\")\n",
    "print(f\"False Positives: {cm_opt[0,1]}\")\n",
    "print(f\"False Negatives: {cm_opt[1,0]}\")\n",
    "print(f\"True Positives: {cm_opt[1,1]}\")\n"
   ],
   "id": "207b168335f3af4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Optimized model evaluation\n",
      "Optimized model performance\n",
      "============================================================\n",
      "Accuracy:  0.7757\n",
      "Precision: 0.5729\n",
      "Recall:    0.6096\n",
      "F1-Score:  0.5907\n",
      "ROC-AUC:   0.8090\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.86      0.84      0.85      1035\n",
      "       Churn       0.57      0.61      0.59       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.71      0.72      0.72      1409\n",
      "weighted avg       0.78      0.78      0.78      1409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[865 170]\n",
      " [146 228]]\n",
      "\n",
      "True Negatives: 865\n",
      "False Positives: 170\n",
      "False Negatives: 146\n",
      "True Positives: 228\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T01:33:57.692290Z",
     "start_time": "2025-12-12T01:33:57.662009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#compare baseline and optimized\n",
    "print(\"Step 6: Baseline VS Optimized comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df= pd.DataFrame({\n",
    "    'Metric':['Accuracy', 'Precision','Recall','F1-Score','ROC-AUC'],\n",
    "    'Baseline':[bs_accuracy,bs_precision,bs_recall,bs_f1,bs_roc_auc],\n",
    "    'Optimized': [optimized_accuracy,optimized_precision, optimized_recall, optimized_f1, optimized_roc_auc]\n",
    "})\n",
    "\n",
    "comparison_df['Improvement'] = ((comparison_df['Optimized'] - comparison_df['Baseline']) / comparison_df['Baseline']*100).round(2)\n",
    "\n",
    "#compare baseline and optimized\n",
    "\n",
    "print(\"Step 6: Baseline VS Optimized comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'Baseline': [bs_accuracy, bs_precision, bs_recall, bs_f1, bs_roc_auc],\n",
    "    'Optimized': [optimized_accuracy, optimized_precision, optimized_recall, optimized_f1, optimized_roc_auc]\n",
    "})\n",
    "\n",
    "comparison_df['Improvement'] = (\n",
    "            (comparison_df['Optimized'] - comparison_df['Baseline']) / comparison_df['Baseline'] * 100).round(2)\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\nImprovement Summary:\")\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    if row['Improvement'] > 0:\n",
    "        print(f\"{row['Metric']}: +{row['Improvement']:.2f}% improvement\")\n",
    "    elif row['Improvement'] < 0:\n",
    "        print(f\"{row['Metric']}: {row['Improvement']:.2f}% decrease\")\n",
    "    else:\n",
    "        print(f\"{row['Metric']}: No change\")\n"
   ],
   "id": "12e5c221ee56f105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Baseline VS Optimized comparison\n",
      "============================================================\n",
      "Step 6: Baseline VS Optimized comparison\n",
      "============================================================\n",
      "\n",
      "Performance Comparison:\n",
      "   Metric  Baseline  Optimized  Improvement\n",
      " Accuracy  0.765791   0.775727         1.30\n",
      "Precision  0.549327   0.572864         4.28\n",
      "   Recall  0.655080   0.609626        -6.94\n",
      " F1-Score  0.597561   0.590674        -1.15\n",
      "  ROC-AUC  0.827559   0.808951        -2.25\n",
      "\n",
      "Improvement Summary:\n",
      "Accuracy: +1.30% improvement\n",
      "Precision: +4.28% improvement\n",
      "Recall: -6.94% decrease\n",
      "F1-Score: -1.15% decrease\n",
      "ROC-AUC: -2.25% decrease\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "81a3ea896f6a2e2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
